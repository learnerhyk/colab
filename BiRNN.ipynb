{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPrznFK3e8uWkqdyGMYKUVs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/learnerwcl/colab/blob/main/BiRNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsuMgs7YCXN9",
        "outputId": "e56946c1-8e17-4f38-8262-698718638e4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-22 15:53:53--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘aclImdb_v1.tar.gz’\n",
            "\n",
            "aclImdb_v1.tar.gz   100%[===================>]  80.23M  24.8MB/s    in 3.4s    \n",
            "\n",
            "2025-01-22 15:53:56 (23.8 MB/s) - ‘aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!cd /content\n",
        "!wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -zxvf aclImdb_v1.tar.gz 2>&1 > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "from collections import Counter\n",
        "import re\n",
        "import os\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import roc_auc_score  # 计算 AUC\n",
        "\n",
        "from tqdm import tqdm  # 可选，用于显示进度条\n",
        "\n",
        "def grad_clipping(net, theta):\n",
        "    if isinstance(net, nn.Module):\n",
        "        params = [p for p in net.parameters() if p.requires_grad]\n",
        "    else:\n",
        "        params = net.params\n",
        "    norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))\n",
        "    if norm > theta:\n",
        "        for param in params:\n",
        "            param.grad[:] *= theta / norm\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
        "    text = text.lower().strip()\n",
        "    return text\n",
        "\n",
        "def build_movie_vocab_chuncked(root_dir, min_freq=20):\n",
        "    counter = Counter()\n",
        "    all_file = glob.glob(os.path.join(root_dir,\"**/*.txt\"), recursive=True)\n",
        "    for fn in all_file:\n",
        "        with open(fn, 'r') as file:\n",
        "            text = file.read()\n",
        "            text = clean_text(text)\n",
        "            words = text.split(\" \")\n",
        "            counter.update(words)\n",
        "\n",
        "    counter = {word:freq for word,freq in counter.items() if freq>=min_freq}\n",
        "    vocab = {word: idx for idx, (word, freq) in enumerate(counter.items(), start=2)}\n",
        "    vocab[\"<PAD>\"] = 0\n",
        "    vocab[\"<UNK>\"] = 1\n",
        "    return vocab"
      ],
      "metadata": {
        "id": "iiLRA_97EYdX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LazyLoader\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "import glob\n",
        "\n",
        "\n",
        "class ImbdDataSet(Dataset):\n",
        "  def __init__(self, root_path, vocab, max_length=128, data_type='trian', transform=None):\n",
        "    self.data_path_list = []\n",
        "    self.label_list = []\n",
        "    self.transform = transform\n",
        "    self.vocab = vocab\n",
        "    self.max_length = max_length\n",
        "\n",
        "    self.root_path = root_path\n",
        "\n",
        "    pos_path = os.path.join(root_path, data_type, 'pos')\n",
        "    neg_path = os.path.join(root_path, data_type, 'neg')\n",
        "\n",
        "    for item in glob.glob(os.path.join(pos_path,\"*.txt\")):\n",
        "      self.label_list.append(1)\n",
        "      self.data_path_list.append(item)\n",
        "\n",
        "    for item in glob.glob(os.path.join(neg_path,\"*.txt\")):\n",
        "      self.label_list.append(0)\n",
        "      self.data_path_list.append(item)\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data_path_list)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    label_ = self.label_list[idx]\n",
        "    path_ = self.data_path_list[idx]\n",
        "    with open(path_,'r') as f:\n",
        "      data_ = f.read()\n",
        "\n",
        "    data_ = clean_text(data_)\n",
        "\n",
        "    words = data_.split(\" \")\n",
        "    data_ = [self.vocab.get(word, self.vocab['<UNK>']) for word in words]\n",
        "\n",
        "    # 将数据处理为定长\n",
        "    if len(data_) > self.max_length:  # 截断\n",
        "        data_ = data_[:self.max_length]\n",
        "    else:  # 填充\n",
        "        data_ = data_ + [self.vocab['<PAD>']] * (self.max_length - len(data_))\n",
        "\n",
        "    if self.transform:\n",
        "        data_ = self.transform(data_)\n",
        "\n",
        "    return torch.tensor(data_, dtype=torch.long), torch.tensor(label_, dtype=torch.long)\n",
        "\n"
      ],
      "metadata": {
        "id": "DlHw8dIQEa3K"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = build_movie_vocab_chuncked(\"/content/aclImdb\", 512)\n",
        "print(f\"vocab size: {len(vocab)}\")\n",
        "train_data = ImbdDataSet(\"/content/aclImdb\", vocab, max_length=128, data_type='train')\n",
        "test_data = ImbdDataSet(\"/content/aclImdb\", vocab, max_length=128, data_type='test')\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cewwc4xYEkqw",
        "outputId": "70b428e9-5d91-470b-9061-83c20b8be982"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab size: 3396\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SimpleRNNLayer(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    super(SimpleRNNLayer, self).__init__()\n",
        "\n",
        "    self.Wxh = nn.Parameter(torch.Tensor(hidden_size, input_size))\n",
        "    self.Whh = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
        "    self.bh = nn.Parameter(torch.Tensor(hidden_size, 1))\n",
        "\n",
        "    self.reset_parameters()\n",
        "\n",
        "  def reset_parameters(self):\n",
        "    nn.init.xavier_uniform_(self.Wxh)\n",
        "    nn.init.xavier_uniform_(self.Whh)\n",
        "    nn.init.zeros_(self.bh)\n",
        "\n",
        "  def forward(self, inputs, h_):\n",
        "    # inputs: (batch_size, input_size)\n",
        "\n",
        "    h_ = torch.tanh(\n",
        "        inputs @ self.Wxh.T +\n",
        "        h_ @ self.Whh.T  +\n",
        "        self.bh.T\n",
        "    )\n",
        "\n",
        "    # outputs: (batch_size, hidden_size)\n",
        "\n",
        "    return h_"
      ],
      "metadata": {
        "id": "zZOMRSPUGm87"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BiRNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size, embedding_size):\n",
        "    super(BiRNN, self).__init__()\n",
        "\n",
        "    self.hidden_size = hidden_size\n",
        "    self.embed = nn.Embedding(input_size, embedding_size)\n",
        "\n",
        "    self.front_rnn = SimpleRNNLayer(embedding_size, hidden_size)\n",
        "    self.back_rnn = SimpleRNNLayer(embedding_size, hidden_size)\n",
        "\n",
        "    self.fc = nn.Linear(2*hidden_size, output_size)\n",
        "\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    hidden_front = torch.zeros(inputs.shape[0], self.hidden_size, device=inputs.device)\n",
        "    hidden_back = torch.zeros(inputs.shape[0], self.hidden_size, device=inputs.device)\n",
        "\n",
        "    # 1. embedding: (batch_size, seq_len, embed_dim)\n",
        "    inputs = self.embed(inputs)\n",
        "\n",
        "    # 2. transpose: (seq_len, batch_size, embed_dim)\n",
        "    inputs = torch.transpose(inputs, 0, 1)\n",
        "\n",
        "    front_outputs = []\n",
        "    back_outputs = []\n",
        "\n",
        "    # 3. x: (batch_size, embed_dim)\n",
        "    for x in inputs:\n",
        "      hidden_front = self.front_rnn(x, hidden_front)\n",
        "      # batch_size, hidden_size\n",
        "      front_outputs.append(hidden_front)\n",
        "\n",
        "    for x in reversed(inputs):\n",
        "      hidden_back = self.back_rnn(x, hidden_back)\n",
        "      # batch_size, hidden_size\n",
        "      back_outputs.append(hidden_back)\n",
        "\n",
        "    back_outputs = back_outputs[::-1]\n",
        "\n",
        "    # 4. concat\n",
        "\n",
        "    hidden = torch.cat((hidden_front, hidden_back), dim=1)\n",
        "\n",
        "    hidden = self.fc(hidden)\n",
        "\n",
        "    return hidden, (front_outputs, back_outputs)"
      ],
      "metadata": {
        "id": "KPsb_wQgHHTw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BiRNN(len(vocab), 128, 2, 128 )  # 定义的网络结构\n",
        "criterion = torch.nn.CrossEntropyLoss()  # 损失函数\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # 优化器\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # 设置设备\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7F8k1xrt5n0",
        "outputId": "8456549b-4dcb-4644-bdd0-cab1c80a1190"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_new(model, dataloader, evalloader, criterion, optimizer, device, scheduler=None, epochs=10):\n",
        "    \"\"\"\n",
        "    训练模型的通用函数。\n",
        "\n",
        "    参数：\n",
        "    - model: 定义好的神经网络模型。\n",
        "    - dataloader: 数据加载器（训练集）。\n",
        "    - criterion: 损失函数。\n",
        "    - optimizer: 优化器。\n",
        "    - device: 训练设备（\"cuda\" 或 \"cpu\"）。\n",
        "    - epochs: 训练轮数。\n",
        "\n",
        "    返回：\n",
        "    - model: 训练后的模型。\n",
        "    - metrics: 包含训练过程中的损失和其他指标。\n",
        "    \"\"\"\n",
        "    model.to(device)  # 将模型加载到设备\n",
        "    metrics = {\"loss\": [], \"auc\": [], 'eval_loss': [], 'eval_auc': []}  # 记录每个 epoch 的损失\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()  # 设置模型为训练模式\n",
        "        if scheduler:\n",
        "          scheduler.step()\n",
        "        epoch_loss = 0.0\n",
        "        all_labels = []  # 存储真实标签\n",
        "        all_probs = []  # 存储预测概率\n",
        "        progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
        "\n",
        "        for batch in progress_bar:\n",
        "            inputs, labels = batch\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # 前向传播\n",
        "            outputs, _  = model(inputs)\n",
        "\n",
        "            # outputs = outputs.squeeze(-1)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # 反向传播\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "\n",
        "            grad_clipping(model, 1)\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            # 累加损失\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            probs = torch.softmax(outputs, dim=1)[:, 1].detach().cpu().numpy()  # 假设二分类，取第二类概率\n",
        "            all_probs.extend(probs)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "\n",
        "        # 记录每个 epoch 的平均损失\n",
        "        avg_loss = epoch_loss / len(dataloader)\n",
        "        metrics[\"loss\"].append(avg_loss)\n",
        "        epoch_auc = roc_auc_score(all_labels, all_probs)\n",
        "        metrics[\"auc\"].append(epoch_auc)\n",
        "\n",
        "        model.eval()\n",
        "        eval_loss = 0.0\n",
        "        eval_labels = []  # 存储真实标签\n",
        "        eval_probs = []  # 存储预测概率\n",
        "\n",
        "        for batch_eval in evalloader:\n",
        "          inputs_eval, labels_eval = batch_eval\n",
        "          inputs_eval, labels_eval = inputs_eval.to(device), labels_eval.to(device)\n",
        "          outputs_eval, _  = model(inputs_eval)\n",
        "          loss_eval = criterion(outputs_eval, labels_eval)\n",
        "          eval_loss += loss_eval.item()\n",
        "          probs = torch.softmax(outputs_eval, dim=1)[:,1].detach().cpu().numpy()\n",
        "          eval_probs.extend(probs)\n",
        "          eval_labels.extend(labels_eval.cpu().numpy())\n",
        "        eval_loss_avg = eval_loss / len(evalloader)\n",
        "        metrics['eval_loss'].append(eval_loss_avg)\n",
        "        eval_auc = roc_auc_score(eval_labels, eval_probs)\n",
        "        metrics['eval_auc'].append(eval_auc)\n",
        "#\n",
        "\n",
        "        # print(f\"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}, AUC: {epoch_auc:.4f}\")\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}, AUC: {epoch_auc:.4f}, Eval Loss: {eval_loss_avg:.4f}, Eval AUC: {eval_auc:.4f}\")\n",
        "\n",
        "    return model, metrics"
      ],
      "metadata": {
        "id": "MV3EfGF9uu4X"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model, metrics = train_model_new(\n",
        "    model=model,\n",
        "    dataloader=train_loader,\n",
        "    evalloader=test_loader,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    device=device,\n",
        "    epochs=30\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_w5JKJxvUW6",
        "outputId": "aba2dcfd-58a9-47e5-eb94-981f9436d0ba"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/30: 100%|██████████| 391/391 [00:42<00:00,  9.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/30], Loss: 0.6880, AUC: 0.5803, Eval Loss: 0.6764, Eval AUC: 0.6214\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/30: 100%|██████████| 391/391 [00:40<00:00,  9.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/30], Loss: 0.6160, AUC: 0.7204, Eval Loss: 0.6198, Eval AUC: 0.7300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/30: 100%|██████████| 391/391 [00:40<00:00,  9.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/30], Loss: 0.5447, AUC: 0.7991, Eval Loss: 0.5839, Eval AUC: 0.7676\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/30: 100%|██████████| 391/391 [00:40<00:00,  9.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/30], Loss: 0.4777, AUC: 0.8527, Eval Loss: 0.5617, Eval AUC: 0.7999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/30: 100%|██████████| 391/391 [00:41<00:00,  9.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/30], Loss: 0.4129, AUC: 0.8931, Eval Loss: 0.5809, Eval AUC: 0.7948\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/30: 100%|██████████| 391/391 [00:41<00:00,  9.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/30], Loss: 0.3538, AUC: 0.9228, Eval Loss: 0.5789, Eval AUC: 0.8130\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/30: 100%|██████████| 391/391 [00:42<00:00,  9.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/30], Loss: 0.2976, AUC: 0.9458, Eval Loss: 0.6409, Eval AUC: 0.7986\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/30: 100%|██████████| 391/391 [00:44<00:00,  8.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/30], Loss: 0.2401, AUC: 0.9649, Eval Loss: 0.6590, Eval AUC: 0.8186\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/30: 100%|██████████| 391/391 [00:42<00:00,  9.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/30], Loss: 0.1854, AUC: 0.9791, Eval Loss: 0.7367, Eval AUC: 0.8176\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/30: 100%|██████████| 391/391 [00:40<00:00,  9.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/30], Loss: 0.1515, AUC: 0.9858, Eval Loss: 0.8348, Eval AUC: 0.8241\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/30: 100%|██████████| 391/391 [00:40<00:00,  9.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [11/30], Loss: 0.1145, AUC: 0.9917, Eval Loss: 0.9192, Eval AUC: 0.8080\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/30: 100%|██████████| 391/391 [00:40<00:00,  9.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [12/30], Loss: 0.0864, AUC: 0.9952, Eval Loss: 1.0015, Eval AUC: 0.8149\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/30: 100%|██████████| 391/391 [00:39<00:00,  9.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [13/30], Loss: 0.0698, AUC: 0.9968, Eval Loss: 1.0644, Eval AUC: 0.8184\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/30: 100%|██████████| 391/391 [00:40<00:00,  9.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [14/30], Loss: 0.0621, AUC: 0.9974, Eval Loss: 1.1766, Eval AUC: 0.7946\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/30: 100%|██████████| 391/391 [00:39<00:00,  9.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [15/30], Loss: 0.0632, AUC: 0.9972, Eval Loss: 1.2067, Eval AUC: 0.8072\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/30: 100%|██████████| 391/391 [00:39<00:00,  9.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [16/30], Loss: 0.0525, AUC: 0.9980, Eval Loss: 1.3603, Eval AUC: 0.7811\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/30: 100%|██████████| 391/391 [00:39<00:00,  9.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [17/30], Loss: 0.0499, AUC: 0.9980, Eval Loss: 1.3471, Eval AUC: 0.8238\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/30: 100%|██████████| 391/391 [00:40<00:00,  9.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [18/30], Loss: 0.0411, AUC: 0.9988, Eval Loss: 1.4263, Eval AUC: 0.8029\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/30: 100%|██████████| 391/391 [00:39<00:00,  9.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [19/30], Loss: 0.0368, AUC: 0.9989, Eval Loss: 1.4661, Eval AUC: 0.8121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/30: 100%|██████████| 391/391 [00:39<00:00,  9.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [20/30], Loss: 0.0350, AUC: 0.9991, Eval Loss: 1.5012, Eval AUC: 0.8112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/30: 100%|██████████| 391/391 [00:40<00:00,  9.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [21/30], Loss: 0.0331, AUC: 0.9991, Eval Loss: 1.5595, Eval AUC: 0.8204\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/30: 100%|██████████| 391/391 [00:39<00:00,  9.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [22/30], Loss: 0.0374, AUC: 0.9989, Eval Loss: 1.5556, Eval AUC: 0.7976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23/30: 100%|██████████| 391/391 [00:41<00:00,  9.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [23/30], Loss: 0.0381, AUC: 0.9989, Eval Loss: 1.6340, Eval AUC: 0.7936\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24/30: 100%|██████████| 391/391 [00:39<00:00,  9.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [24/30], Loss: 0.0388, AUC: 0.9988, Eval Loss: 1.6127, Eval AUC: 0.7974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25/30: 100%|██████████| 391/391 [00:39<00:00,  9.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [25/30], Loss: 0.0358, AUC: 0.9990, Eval Loss: 1.6460, Eval AUC: 0.8096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26/30: 100%|██████████| 391/391 [00:39<00:00,  9.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [26/30], Loss: 0.0321, AUC: 0.9992, Eval Loss: 1.7284, Eval AUC: 0.8063\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27/30: 100%|██████████| 391/391 [00:41<00:00,  9.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [27/30], Loss: 0.0449, AUC: 0.9985, Eval Loss: 1.7123, Eval AUC: 0.8103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28/30: 100%|██████████| 391/391 [00:41<00:00,  9.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [28/30], Loss: 0.0283, AUC: 0.9994, Eval Loss: 1.7569, Eval AUC: 0.8172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29/30: 100%|██████████| 391/391 [00:40<00:00,  9.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [29/30], Loss: 0.0254, AUC: 0.9995, Eval Loss: 1.8060, Eval AUC: 0.8139\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30/30: 100%|██████████| 391/391 [00:39<00:00,  9.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [30/30], Loss: 0.0299, AUC: 0.9993, Eval Loss: 1.8659, Eval AUC: 0.8207\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleGRULayer(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    super(SimpleGRULayer, self).__init__()\n",
        "\n",
        "    self.Wxr = nn.Parameter(torch.Tensor(hidden_size, input_size))\n",
        "    self.Whr = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
        "    self.br = nn.Parameter(torch.Tensor(hidden_size, 1))\n",
        "\n",
        "    self.Wxz = nn.Parameter(torch.Tensor(hidden_size, input_size))\n",
        "    self.Whz = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
        "    self.bz = nn.Parameter(torch.Tensor(hidden_size, 1))\n",
        "\n",
        "    self.Wxh = nn.Parameter(torch.Tensor(hidden_size, input_size))\n",
        "    self.Whh = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
        "    self.bh = nn.Parameter(torch.Tensor(hidden_size, 1))\n",
        "\n",
        "    self.reset_parameters()\n",
        "\n",
        "  def reset_parameters(self):\n",
        "    nn.init.xavier_uniform_(self.Wxr)\n",
        "    nn.init.xavier_uniform_(self.Whr)\n",
        "    nn.init.zeros_(self.br)\n",
        "\n",
        "    nn.init.xavier_uniform_(self.Wxz)\n",
        "    nn.init.xavier_uniform_(self.Whz)\n",
        "    nn.init.zeros_(self.bz)\n",
        "\n",
        "    nn.init.xavier_uniform_(self.Wxh)\n",
        "    nn.init.xavier_uniform_(self.Whh)\n",
        "    nn.init.zeros_(self.bh)\n",
        "\n",
        "  def forward(self, inputs, h_):\n",
        "    # inputs: (batch_size, input_size)\n",
        "\n",
        "    r_ = torch.sigmoid(\n",
        "       inputs @ self.Wxr.T +\n",
        "       h_ @ self.Whr.T +\n",
        "       self.br.T\n",
        "    )\n",
        "\n",
        "    z_ = torch.sigmoid(\n",
        "       inputs @ self.Wxz.T +\n",
        "       h_ @ self.Whz.T +\n",
        "       self.bz.T\n",
        "    )\n",
        "\n",
        "    h_hat = torch.tanh(\n",
        "        inputs @ self.Wxh.T +\n",
        "        (r_ * h_) @ self.Whh.T  +\n",
        "        self.bh.T\n",
        "    )\n",
        "\n",
        "    h_ = z_ * h_ + (1 - z_) * h_hat\n",
        "\n",
        "    # outputs: (batch_size, hidden_size)\n",
        "\n",
        "    return h_"
      ],
      "metadata": {
        "id": "Q2zBcA23vVg6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " class BiGRU(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size, embedding_size):\n",
        "    super(BiGRU, self).__init__()\n",
        "\n",
        "    self.hidden_size = hidden_size\n",
        "    self.embed = nn.Embedding(input_size, embedding_size)\n",
        "\n",
        "    self.front_rnn = SimpleGRULayer(embedding_size, hidden_size)\n",
        "    self.back_rnn = SimpleGRULayer(embedding_size, hidden_size)\n",
        "\n",
        "    self.fc = nn.Linear(2*hidden_size, output_size)\n",
        "\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    hidden_front = torch.zeros(inputs.shape[0], self.hidden_size, device=inputs.device)\n",
        "    hidden_back = torch.zeros(inputs.shape[0], self.hidden_size, device=inputs.device)\n",
        "\n",
        "    # 1. embedding: (batch_size, seq_len, embed_dim)\n",
        "    inputs = self.embed(inputs)\n",
        "\n",
        "    # 2. transpose: (seq_len, batch_size, embed_dim)\n",
        "    inputs = torch.transpose(inputs, 0, 1)\n",
        "\n",
        "    front_outputs = []\n",
        "    back_outputs = []\n",
        "\n",
        "    # 3. x: (batch_size, embed_dim)\n",
        "    for x in inputs:\n",
        "      hidden_front = self.front_rnn(x, hidden_front)\n",
        "      # batch_size, hidden_size\n",
        "      front_outputs.append(hidden_front)\n",
        "\n",
        "    for x in reversed(inputs):\n",
        "      hidden_back = self.back_rnn(x, hidden_back)\n",
        "      # batch_size, hidden_size\n",
        "      back_outputs.append(hidden_back)\n",
        "\n",
        "    back_outputs = back_outputs[::-1]\n",
        "\n",
        "    # 4. concat\n",
        "\n",
        "    hidden = torch.cat((hidden_front, hidden_back), dim=1)\n",
        "\n",
        "    hidden = self.fc(hidden)\n",
        "\n",
        "    return hidden, (front_outputs, back_outputs)"
      ],
      "metadata": {
        "id": "P-RP1W_wwGzg"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = build_movie_vocab_chuncked(\"/content/aclImdb\", 512)\n",
        "print(f\"vocab size: {len(vocab)}\")\n",
        "train_data = ImbdDataSet(\"/content/aclImdb\", vocab, max_length=256, data_type='train')\n",
        "test_data = ImbdDataSet(\"/content/aclImdb\", vocab, max_length=256, data_type='test')\n",
        "train_loader = DataLoader(train_data, batch_size=512, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=512, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A954mhpfEss9",
        "outputId": "60a246cd-c467-4d3e-fa63-2385de333b71"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab size: 3396\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = BiGRU(len(vocab), 128, 2, 128 )  # 定义的网络结构\n",
        "criterion = torch.nn.CrossEntropyLoss()  # 损失函数\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # 优化器\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # 设置设备\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-JJevj-Bb6F",
        "outputId": "f380c4ed-8b00-45d2-9c72-ceccb782a58d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model, metrics = train_model_new(\n",
        "    model=model,\n",
        "    dataloader=train_loader,\n",
        "    evalloader=test_loader,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    device=device,\n",
        "    epochs=10\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JaVa_C8BfYO",
        "outputId": "a0dd6333-ad39-445c-cd61-689969bd637f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10: 100%|██████████| 49/49 [00:38<00:00,  1.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.6794, AUC: 0.5929, Eval Loss: 0.6580, Eval AUC: 0.6481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10: 100%|██████████| 49/49 [00:39<00:00,  1.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/10], Loss: 0.5720, AUC: 0.7701, Eval Loss: 0.5480, Eval AUC: 0.8236\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10: 100%|██████████| 49/49 [00:39<00:00,  1.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/10], Loss: 0.4453, AUC: 0.8749, Eval Loss: 0.4825, Eval AUC: 0.8523\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10: 100%|██████████| 49/49 [00:38<00:00,  1.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/10], Loss: 0.3677, AUC: 0.9163, Eval Loss: 0.4191, Eval AUC: 0.8911\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10: 100%|██████████| 49/49 [00:39<00:00,  1.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/10], Loss: 0.3112, AUC: 0.9405, Eval Loss: 0.4068, Eval AUC: 0.9042\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/10:  92%|█████████▏| 45/49 [00:36<00:03,  1.22it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleLSTMLayer(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    super(SimpleLSTMLayer, self).__init__()\n",
        "\n",
        "    self.Wxi = nn.Parameter(torch.Tensor(hidden_size, input_size))\n",
        "    self.Whi = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
        "    self.bi = nn.Parameter(torch.Tensor(hidden_size, 1))\n",
        "\n",
        "    self.Wxf = nn.Parameter(torch.Tensor(hidden_size, input_size))\n",
        "    self.Whf = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
        "    self.bf = nn.Parameter(torch.Tensor(hidden_size, 1))\n",
        "\n",
        "    self.Wxo = nn.Parameter(torch.Tensor(hidden_size, input_size))\n",
        "    self.Who = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
        "    self.bo = nn.Parameter(torch.Tensor(hidden_size, 1))\n",
        "\n",
        "    self.Wxc = nn.Parameter(torch.Tensor(hidden_size, input_size))\n",
        "    self.Whc = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
        "    self.bc = nn.Parameter(torch.Tensor(hidden_size, 1))\n",
        "\n",
        "    self.reset_parameters()\n",
        "\n",
        "  def reset_parameters(self):\n",
        "    nn.init.xavier_uniform_(self.Wxi)\n",
        "    nn.init.xavier_uniform_(self.Whi)\n",
        "    nn.init.zeros_(self.bi)\n",
        "\n",
        "    nn.init.xavier_uniform_(self.Wxf)\n",
        "    nn.init.xavier_uniform_(self.Whf)\n",
        "    nn.init.zeros_(self.bf)\n",
        "\n",
        "    nn.init.xavier_uniform_(self.Wxo)\n",
        "    nn.init.xavier_uniform_(self.Who)\n",
        "    nn.init.zeros_(self.bo)\n",
        "\n",
        "    nn.init.xavier_uniform_(self.Wxc)\n",
        "    nn.init.xavier_uniform_(self.Whc)\n",
        "    nn.init.zeros_(self.bc)\n",
        "\n",
        "  def forward(self, inputs, h_, c_):\n",
        "    # inputs: (batch_size, input_size)\n",
        "\n",
        "    i_ = torch.sigmoid(\n",
        "       inputs @ self.Wxi.T +\n",
        "       h_ @ self.Whi.T +\n",
        "       self.bi.T\n",
        "    )\n",
        "\n",
        "    f_ = torch.sigmoid(\n",
        "       inputs @ self.Wxf.T +\n",
        "       h_ @ self.Whf.T +\n",
        "       self.bf.T\n",
        "    )\n",
        "\n",
        "    o_ = torch.sigmoid(\n",
        "       inputs @ self.Wxo.T +\n",
        "       h_ @ self.Who.T +\n",
        "       self.bo.T\n",
        "    )\n",
        "\n",
        "    c_hat = torch.tanh(\n",
        "        inputs @ self.Wxc.T +\n",
        "        h_ @ self.Whc.T +\n",
        "        self.bc.T\n",
        "    )\n",
        "\n",
        "    c_ = f_ * c_ + i_ * c_hat\n",
        "\n",
        "    h_ = o_ * torch.tanh(c_)\n",
        "\n",
        "    # outputs: (batch_size, hidden_size)\n",
        "\n",
        "    return h_, c_"
      ],
      "metadata": {
        "id": "DDmKl6Z1BmvF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " class BiLSTM(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size, embedding_size):\n",
        "    super(BiLSTM, self).__init__()\n",
        "\n",
        "    self.hidden_size = hidden_size\n",
        "    self.embed = nn.Embedding(input_size, embedding_size)\n",
        "\n",
        "    self.front_rnn = SimpleLSTMLayer(embedding_size, hidden_size)\n",
        "    self.back_rnn = SimpleLSTMLayer(embedding_size, hidden_size)\n",
        "\n",
        "    self.fc = nn.Linear(2*hidden_size, output_size)\n",
        "\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    hidden_front = torch.zeros(inputs.shape[0], self.hidden_size, device=inputs.device)\n",
        "    hidden_back = torch.zeros(inputs.shape[0], self.hidden_size, device=inputs.device)\n",
        "\n",
        "    cell_front = torch.zeros(inputs.shape[0], self.hidden_size, device=inputs.device)\n",
        "    cell_back = torch.zeros(inputs.shape[0], self.hidden_size, device=inputs.device)\n",
        "\n",
        "    # 1. embedding: (batch_size, seq_len, embed_dim)\n",
        "    inputs = self.embed(inputs)\n",
        "\n",
        "    # 2. transpose: (seq_len, batch_size, embed_dim)\n",
        "    inputs = torch.transpose(inputs, 0, 1)\n",
        "\n",
        "    front_outputs = []\n",
        "    back_outputs = []\n",
        "\n",
        "    front_cells = []\n",
        "    back_cells = []\n",
        "\n",
        "    # 3. x: (batch_size, embed_dim)\n",
        "    for x in inputs:\n",
        "      hidden_front, cell_front = self.front_rnn(x, hidden_front, cell_front)\n",
        "      # batch_size, hidden_size\n",
        "      front_outputs.append(hidden_front)\n",
        "      front_cells.append(cell_front)\n",
        "\n",
        "    for x in reversed(inputs):\n",
        "      hidden_back, cell_back = self.back_rnn(x, hidden_back, cell_back)\n",
        "      # batch_size, hidden_size\n",
        "      back_outputs.append(hidden_back)\n",
        "      back_cells.append(cell_back)\n",
        "\n",
        "    back_outputs = back_outputs[::-1]\n",
        "\n",
        "    # 4. concat\n",
        "\n",
        "    hidden = torch.cat((hidden_front, hidden_back), dim=1)\n",
        "\n",
        "    hidden = self.fc(hidden)\n",
        "\n",
        "    return hidden, (front_outputs, back_outputs)"
      ],
      "metadata": {
        "id": "5mYgZ_baLzS3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = build_movie_vocab_chuncked(\"/content/aclImdb\", 256)\n",
        "print(f\"vocab size: {len(vocab)}\")\n",
        "train_data = ImbdDataSet(\"/content/aclImdb\", vocab, max_length=256, data_type='train')\n",
        "test_data = ImbdDataSet(\"/content/aclImdb\", vocab, max_length=256, data_type='test')\n",
        "train_loader = DataLoader(train_data, batch_size=1024, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=1024, shuffle=False)"
      ],
      "metadata": {
        "id": "0pPXwp92uJ97",
        "outputId": "0ec62da4-0e44-4c2b-b561-8b1e03368cc1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab size: 5817\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = BiLSTM(len(vocab), 128, 2, 128 )  # 定义的网络结构\n",
        "criterion = torch.nn.CrossEntropyLoss()  # 损失函数\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # 优化器\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # 设置设备\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "print(device)"
      ],
      "metadata": {
        "id": "Zg46LexCu1-r",
        "outputId": "01f64062-ea34-4990-b84a-6577858405ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model, metrics = train_model_new(\n",
        "    model=model,\n",
        "    dataloader=train_loader,\n",
        "    evalloader=test_loader,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    device=device,\n",
        "    epochs=30\n",
        ")"
      ],
      "metadata": {
        "id": "su-g57OHt_d4",
        "outputId": "846dd9d2-fa61-4980-d3c9-3181c38575fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/30: 100%|██████████| 25/25 [00:25<00:00,  1.03s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/30], Loss: 0.6884, AUC: 0.5525, Eval Loss: 0.6796, Eval AUC: 0.5959\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/30: 100%|██████████| 25/25 [00:25<00:00,  1.01s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/30], Loss: 0.6551, AUC: 0.6573, Eval Loss: 0.6221, Eval AUC: 0.7072\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/30: 100%|██████████| 25/25 [00:24<00:00,  1.02it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/30], Loss: 0.5521, AUC: 0.7926, Eval Loss: 0.5249, Eval AUC: 0.8167\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/30: 100%|██████████| 25/25 [00:25<00:00,  1.02s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/30], Loss: 0.4817, AUC: 0.8508, Eval Loss: 0.4937, Eval AUC: 0.8488\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/30: 100%|██████████| 25/25 [00:25<00:00,  1.02s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/30], Loss: 0.4070, AUC: 0.8970, Eval Loss: 0.4731, Eval AUC: 0.8729\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/30: 100%|██████████| 25/25 [00:24<00:00,  1.00it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/30], Loss: 0.3668, AUC: 0.9165, Eval Loss: 0.4292, Eval AUC: 0.8855\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/30: 100%|██████████| 25/25 [00:24<00:00,  1.01it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/30], Loss: 0.3363, AUC: 0.9296, Eval Loss: 0.4212, Eval AUC: 0.8927\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/30: 100%|██████████| 25/25 [00:24<00:00,  1.02it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/30], Loss: 0.3060, AUC: 0.9416, Eval Loss: 0.4249, Eval AUC: 0.8980\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/30: 100%|██████████| 25/25 [00:24<00:00,  1.01it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [9/30], Loss: 0.2594, AUC: 0.9581, Eval Loss: 0.4088, Eval AUC: 0.9031\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/30: 100%|██████████| 25/25 [00:24<00:00,  1.02it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [10/30], Loss: 0.2283, AUC: 0.9674, Eval Loss: 0.4164, Eval AUC: 0.9023\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11/30: 100%|██████████| 25/25 [00:24<00:00,  1.03it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [11/30], Loss: 0.2172, AUC: 0.9707, Eval Loss: 0.4339, Eval AUC: 0.9038\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12/30: 100%|██████████| 25/25 [00:25<00:00,  1.03s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [12/30], Loss: 0.1733, AUC: 0.9805, Eval Loss: 0.4465, Eval AUC: 0.9022\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/30: 100%|██████████| 25/25 [00:24<00:00,  1.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [13/30], Loss: 0.1642, AUC: 0.9822, Eval Loss: 0.4675, Eval AUC: 0.9002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/30: 100%|██████████| 25/25 [00:24<00:00,  1.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [14/30], Loss: 0.1281, AUC: 0.9883, Eval Loss: 0.4690, Eval AUC: 0.9031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/30: 100%|██████████| 25/25 [00:24<00:00,  1.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [15/30], Loss: 0.1180, AUC: 0.9900, Eval Loss: 0.5142, Eval AUC: 0.9011\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/30: 100%|██████████| 25/25 [00:24<00:00,  1.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [16/30], Loss: 0.1078, AUC: 0.9914, Eval Loss: 0.5767, Eval AUC: 0.8951\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/30: 100%|██████████| 25/25 [00:24<00:00,  1.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [17/30], Loss: 0.1049, AUC: 0.9921, Eval Loss: 0.5287, Eval AUC: 0.9000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/30: 100%|██████████| 25/25 [00:24<00:00,  1.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [18/30], Loss: 0.0935, AUC: 0.9932, Eval Loss: 0.6235, Eval AUC: 0.8944\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/30: 100%|██████████| 25/25 [00:24<00:00,  1.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [19/30], Loss: 0.0829, AUC: 0.9944, Eval Loss: 0.6128, Eval AUC: 0.8975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/30: 100%|██████████| 25/25 [00:24<00:00,  1.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [20/30], Loss: 0.0613, AUC: 0.9963, Eval Loss: 0.6159, Eval AUC: 0.8980\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/30: 100%|██████████| 25/25 [00:24<00:00,  1.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [21/30], Loss: 0.0679, AUC: 0.9960, Eval Loss: 0.6419, Eval AUC: 0.8953\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/30: 100%|██████████| 25/25 [00:24<00:00,  1.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [22/30], Loss: 0.0618, AUC: 0.9966, Eval Loss: 0.6494, Eval AUC: 0.8960\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23/30: 100%|██████████| 25/25 [00:24<00:00,  1.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [23/30], Loss: 0.0527, AUC: 0.9974, Eval Loss: 0.6949, Eval AUC: 0.8904\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24/30: 100%|██████████| 25/25 [00:24<00:00,  1.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [24/30], Loss: 0.0500, AUC: 0.9975, Eval Loss: 0.6648, Eval AUC: 0.8906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25/30: 100%|██████████| 25/25 [00:24<00:00,  1.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [25/30], Loss: 0.0382, AUC: 0.9981, Eval Loss: 0.8405, Eval AUC: 0.8867\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26/30: 100%|██████████| 25/25 [00:24<00:00,  1.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [26/30], Loss: 0.0391, AUC: 0.9982, Eval Loss: 0.6427, Eval AUC: 0.8985\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27/30: 100%|██████████| 25/25 [00:24<00:00,  1.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [27/30], Loss: 0.0355, AUC: 0.9984, Eval Loss: 0.7479, Eval AUC: 0.8893\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28/30: 100%|██████████| 25/25 [00:24<00:00,  1.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [28/30], Loss: 0.0282, AUC: 0.9988, Eval Loss: 0.8050, Eval AUC: 0.8944\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29/30: 100%|██████████| 25/25 [00:24<00:00,  1.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [29/30], Loss: 0.0219, AUC: 0.9991, Eval Loss: 0.8323, Eval AUC: 0.8915\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30/30: 100%|██████████| 25/25 [00:24<00:00,  1.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [30/30], Loss: 0.0260, AUC: 0.9990, Eval Loss: 0.7653, Eval AUC: 0.8890\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d8P6eZVnzTSs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}