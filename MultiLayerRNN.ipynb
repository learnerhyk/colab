{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyPmdX1U4meBIPA5A3LvqKlb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/learnerwcl/colab/blob/main/MultiLayerRNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Xl6-7YYErCl",
        "outputId": "694ce496-f46c-4f6e-93e4-ecc895e35bcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-23 05:22:36--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘aclImdb_v1.tar.gz’\n",
            "\n",
            "aclImdb_v1.tar.gz   100%[===================>]  80.23M  8.26MB/s    in 11s     \n",
            "\n",
            "2025-01-23 05:22:48 (7.14 MB/s) - ‘aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!cd /content\n",
        "!wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -zxvf aclImdb_v1.tar.gz 2>&1 > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "from collections import Counter\n",
        "import re\n",
        "import os\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import roc_auc_score  # 计算 AUC\n",
        "\n",
        "from tqdm import tqdm  # 可选，用于显示进度条\n",
        "\n",
        "def grad_clipping(net, theta):\n",
        "    if isinstance(net, nn.Module):\n",
        "        params = [p for p in net.parameters() if p.requires_grad]\n",
        "    else:\n",
        "        params = net.params\n",
        "    norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))\n",
        "    if norm > theta:\n",
        "        for param in params:\n",
        "            param.grad[:] *= theta / norm\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
        "    text = text.lower().strip()\n",
        "    return text\n",
        "\n",
        "def build_movie_vocab_chuncked(root_dir, min_freq=20):\n",
        "    counter = Counter()\n",
        "    all_file = glob.glob(os.path.join(root_dir,\"**/*.txt\"), recursive=True)\n",
        "    for fn in all_file:\n",
        "        with open(fn, 'r') as file:\n",
        "            text = file.read()\n",
        "            text = clean_text(text)\n",
        "            words = text.split(\" \")\n",
        "            counter.update(words)\n",
        "\n",
        "    counter = {word:freq for word,freq in counter.items() if freq>=min_freq}\n",
        "    vocab = {word: idx for idx, (word, freq) in enumerate(counter.items(), start=2)}\n",
        "    vocab[\"<PAD>\"] = 0\n",
        "    vocab[\"<UNK>\"] = 1\n",
        "    return vocab"
      ],
      "metadata": {
        "id": "oBDNg-_KE19r"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "from collections import Counter\n",
        "import re\n",
        "import os\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
        "    text = text.lower().strip()\n",
        "    return text\n",
        "\n",
        "def build_movie_vocab_chuncked(root_dir, min_freq=20):\n",
        "    counter = Counter()\n",
        "    all_file = glob.glob(os.path.join(root_dir,\"**/*.txt\"), recursive=True)\n",
        "    for fn in all_file:\n",
        "        with open(fn, 'r') as file:\n",
        "            text = file.read()\n",
        "            text = clean_text(text)\n",
        "            words = text.split(\" \")\n",
        "            counter.update(words)\n",
        "\n",
        "    counter = {word:freq for word,freq in counter.items() if freq>=min_freq}\n",
        "    vocab = {word: idx for idx, (word, freq) in enumerate(counter.items(), start=2)}\n",
        "    vocab[\"<PAD>\"] = 0\n",
        "    vocab[\"<UNK>\"] = 1\n",
        "    return vocab\n"
      ],
      "metadata": {
        "id": "ZBmnfpX5E4O9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_new(model, dataloader, evalloader, criterion, optimizer, device, scheduler=None, epochs=10):\n",
        "    \"\"\"\n",
        "    训练模型的通用函数。\n",
        "\n",
        "    参数：\n",
        "    - model: 定义好的神经网络模型。\n",
        "    - dataloader: 数据加载器（训练集）。\n",
        "    - criterion: 损失函数。\n",
        "    - optimizer: 优化器。\n",
        "    - device: 训练设备（\"cuda\" 或 \"cpu\"）。\n",
        "    - epochs: 训练轮数。\n",
        "\n",
        "    返回：\n",
        "    - model: 训练后的模型。\n",
        "    - metrics: 包含训练过程中的损失和其他指标。\n",
        "    \"\"\"\n",
        "    model.to(device)  # 将模型加载到设备\n",
        "    metrics = {\"loss\": [], \"auc\": [], 'eval_loss': [], 'eval_auc': []}  # 记录每个 epoch 的损失\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()  # 设置模型为训练模式\n",
        "        if scheduler:\n",
        "          scheduler.step()\n",
        "        epoch_loss = 0.0\n",
        "        all_labels = []  # 存储真实标签\n",
        "        all_probs = []  # 存储预测概率\n",
        "        progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
        "\n",
        "        for batch in progress_bar:\n",
        "            inputs, labels = batch\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # 前向传播\n",
        "            outputs, _  = model(inputs)\n",
        "\n",
        "            # outputs = outputs.squeeze(-1)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # 反向传播\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "\n",
        "            grad_clipping(model, 1)\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            # 累加损失\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            probs = torch.softmax(outputs, dim=1)[:, 1].detach().cpu().numpy()  # 假设二分类，取第二类概率\n",
        "            all_probs.extend(probs)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "\n",
        "        # 记录每个 epoch 的平均损失\n",
        "        avg_loss = epoch_loss / len(dataloader)\n",
        "        metrics[\"loss\"].append(avg_loss)\n",
        "        epoch_auc = roc_auc_score(all_labels, all_probs)\n",
        "        metrics[\"auc\"].append(epoch_auc)\n",
        "\n",
        "        model.eval()\n",
        "        eval_loss = 0.0\n",
        "        eval_labels = []  # 存储真实标签\n",
        "        eval_probs = []  # 存储预测概率\n",
        "\n",
        "        for batch_eval in evalloader:\n",
        "          inputs_eval, labels_eval = batch_eval\n",
        "          inputs_eval, labels_eval = inputs_eval.to(device), labels_eval.to(device)\n",
        "          outputs_eval, _  = model(inputs_eval)\n",
        "          loss_eval = criterion(outputs_eval, labels_eval)\n",
        "          eval_loss += loss_eval.item()\n",
        "          probs = torch.softmax(outputs_eval, dim=1)[:,1].detach().cpu().numpy()\n",
        "          eval_probs.extend(probs)\n",
        "          eval_labels.extend(labels_eval.cpu().numpy())\n",
        "        eval_loss_avg = eval_loss / len(evalloader)\n",
        "        metrics['eval_loss'].append(eval_loss_avg)\n",
        "        eval_auc = roc_auc_score(eval_labels, eval_probs)\n",
        "        metrics['eval_auc'].append(eval_auc)\n",
        "#\n",
        "\n",
        "        # print(f\"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}, AUC: {epoch_auc:.4f}\")\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}, AUC: {epoch_auc:.4f}, Eval Loss: {eval_loss_avg:.4f}, Eval AUC: {eval_auc:.4f}\")\n",
        "\n",
        "    return model, metrics"
      ],
      "metadata": {
        "id": "48l7DHEtGvXm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LazyLoader\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "import glob\n",
        "\n",
        "\n",
        "class ImbdDataSet(Dataset):\n",
        "  def __init__(self, root_path, vocab, max_length=128, data_type='trian', transform=None):\n",
        "    self.data_path_list = []\n",
        "    self.label_list = []\n",
        "    self.transform = transform\n",
        "    self.vocab = vocab\n",
        "    self.max_length = max_length\n",
        "\n",
        "    self.root_path = root_path\n",
        "\n",
        "    pos_path = os.path.join(root_path, data_type, 'pos')\n",
        "    neg_path = os.path.join(root_path, data_type, 'neg')\n",
        "\n",
        "    for item in glob.glob(os.path.join(pos_path,\"*.txt\")):\n",
        "      self.label_list.append(1)\n",
        "      self.data_path_list.append(item)\n",
        "\n",
        "    for item in glob.glob(os.path.join(neg_path,\"*.txt\")):\n",
        "      self.label_list.append(0)\n",
        "      self.data_path_list.append(item)\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data_path_list)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    label_ = self.label_list[idx]\n",
        "    path_ = self.data_path_list[idx]\n",
        "    with open(path_,'r') as f:\n",
        "      data_ = f.read()\n",
        "\n",
        "    data_ = clean_text(data_)\n",
        "\n",
        "    words = data_.split(\" \")\n",
        "    data_ = [self.vocab.get(word, self.vocab['<UNK>']) for word in words]\n",
        "\n",
        "    # 将数据处理为定长\n",
        "    if len(data_) > self.max_length:  # 截断\n",
        "        data_ = data_[:self.max_length]\n",
        "    else:  # 填充\n",
        "        data_ = data_ + [self.vocab['<PAD>']] * (self.max_length - len(data_))\n",
        "\n",
        "    if self.transform:\n",
        "        data_ = self.transform(data_)\n",
        "\n",
        "    return torch.tensor(data_, dtype=torch.long), torch.tensor(label_, dtype=torch.long)\n",
        "\n"
      ],
      "metadata": {
        "id": "S7tPpiviE6Ar"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = build_movie_vocab_chuncked(\"/content/aclImdb\", 256)\n",
        "print(f\"vocab size: {len(vocab)}\")\n",
        "train_data = ImbdDataSet(\"/content/aclImdb\", vocab, max_length=256, data_type='train')\n",
        "test_data = ImbdDataSet(\"/content/aclImdb\", vocab, max_length=256, data_type='test')\n",
        "train_loader = DataLoader(train_data, batch_size=2048, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=2048, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWVldbf2E7yb",
        "outputId": "c0af119e-2de3-4439-8c86-e8a2c0269e03"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab size: 5817\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SimpleRNNLayer(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    super(SimpleRNNLayer, self).__init__()\n",
        "\n",
        "    self.Wxh = nn.Parameter(torch.Tensor(hidden_size, input_size))\n",
        "    self.Whh = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
        "    self.bh = nn.Parameter(torch.Tensor(hidden_size, 1))\n",
        "\n",
        "    self.reset_parameters()\n",
        "\n",
        "  def reset_parameters(self):\n",
        "    nn.init.xavier_uniform_(self.Wxh)\n",
        "    nn.init.xavier_uniform_(self.Whh)\n",
        "    nn.init.zeros_(self.bh)\n",
        "\n",
        "  def forward(self, inputs, h_):\n",
        "    # inputs: (batch_size, input_size)\n",
        "\n",
        "    h_ = torch.tanh(\n",
        "        inputs @ self.Wxh.T +\n",
        "        h_ @ self.Whh.T  +\n",
        "        self.bh.T\n",
        "    )\n",
        "\n",
        "    # outputs: (batch_size, hidden_size)\n",
        "\n",
        "    return h_"
      ],
      "metadata": {
        "id": "nAP1-74LFBnm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleGRULayer(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    super(SimpleGRULayer, self).__init__()\n",
        "\n",
        "    self.Wxr = nn.Parameter(torch.Tensor(hidden_size, input_size))\n",
        "    self.Whr = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
        "    self.br = nn.Parameter(torch.Tensor(hidden_size, 1))\n",
        "\n",
        "    self.Wxz = nn.Parameter(torch.Tensor(hidden_size, input_size))\n",
        "    self.Whz = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
        "    self.bz = nn.Parameter(torch.Tensor(hidden_size, 1))\n",
        "\n",
        "    self.Wxh = nn.Parameter(torch.Tensor(hidden_size, input_size))\n",
        "    self.Whh = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
        "    self.bh = nn.Parameter(torch.Tensor(hidden_size, 1))\n",
        "\n",
        "    self.reset_parameters()\n",
        "\n",
        "  def reset_parameters(self):\n",
        "    nn.init.xavier_uniform_(self.Wxr)\n",
        "    nn.init.xavier_uniform_(self.Whr)\n",
        "    nn.init.zeros_(self.br)\n",
        "\n",
        "    nn.init.xavier_uniform_(self.Wxz)\n",
        "    nn.init.xavier_uniform_(self.Whz)\n",
        "    nn.init.zeros_(self.bz)\n",
        "\n",
        "    nn.init.xavier_uniform_(self.Wxh)\n",
        "    nn.init.xavier_uniform_(self.Whh)\n",
        "    nn.init.zeros_(self.bh)\n",
        "\n",
        "  def forward(self, inputs, h_):\n",
        "    # inputs: (batch_size, input_size)\n",
        "\n",
        "    r_ = torch.sigmoid(\n",
        "       inputs @ self.Wxr.T +\n",
        "       h_ @ self.Whr.T +\n",
        "       self.br.T\n",
        "    )\n",
        "\n",
        "    z_ = torch.sigmoid(\n",
        "       inputs @ self.Wxz.T +\n",
        "       h_ @ self.Whz.T +\n",
        "       self.bz.T\n",
        "    )\n",
        "\n",
        "    h_hat = torch.tanh(\n",
        "        inputs @ self.Wxh.T +\n",
        "        (r_ * h_) @ self.Whh.T  +\n",
        "        self.bh.T\n",
        "    )\n",
        "\n",
        "    h_ = z_ * h_ + (1 - z_) * h_hat\n",
        "\n",
        "    # outputs: (batch_size, hidden_size)\n",
        "\n",
        "    return h_"
      ],
      "metadata": {
        "id": "Jx6IZwMVFGDW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleLSTMLayer(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    super(SimpleLSTMLayer, self).__init__()\n",
        "\n",
        "    self.Wxi = nn.Parameter(torch.Tensor(hidden_size, input_size))\n",
        "    self.Whi = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
        "    self.bi = nn.Parameter(torch.Tensor(hidden_size, 1))\n",
        "\n",
        "    self.Wxf = nn.Parameter(torch.Tensor(hidden_size, input_size))\n",
        "    self.Whf = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
        "    self.bf = nn.Parameter(torch.Tensor(hidden_size, 1))\n",
        "\n",
        "    self.Wxo = nn.Parameter(torch.Tensor(hidden_size, input_size))\n",
        "    self.Who = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
        "    self.bo = nn.Parameter(torch.Tensor(hidden_size, 1))\n",
        "\n",
        "    self.Wxc = nn.Parameter(torch.Tensor(hidden_size, input_size))\n",
        "    self.Whc = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
        "    self.bc = nn.Parameter(torch.Tensor(hidden_size, 1))\n",
        "\n",
        "    self.reset_parameters()\n",
        "\n",
        "  def reset_parameters(self):\n",
        "    nn.init.xavier_uniform_(self.Wxi)\n",
        "    nn.init.xavier_uniform_(self.Whi)\n",
        "    nn.init.zeros_(self.bi)\n",
        "\n",
        "    nn.init.xavier_uniform_(self.Wxf)\n",
        "    nn.init.xavier_uniform_(self.Whf)\n",
        "    nn.init.zeros_(self.bf)\n",
        "\n",
        "    nn.init.xavier_uniform_(self.Wxo)\n",
        "    nn.init.xavier_uniform_(self.Who)\n",
        "    nn.init.zeros_(self.bo)\n",
        "\n",
        "    nn.init.xavier_uniform_(self.Wxc)\n",
        "    nn.init.xavier_uniform_(self.Whc)\n",
        "    nn.init.zeros_(self.bc)\n",
        "\n",
        "  def forward(self, inputs, h_, c_):\n",
        "    # inputs: (batch_size, input_size)\n",
        "\n",
        "    i_ = torch.sigmoid(\n",
        "       inputs @ self.Wxi.T +\n",
        "       h_ @ self.Whi.T +\n",
        "       self.bi.T\n",
        "    )\n",
        "\n",
        "    f_ = torch.sigmoid(\n",
        "       inputs @ self.Wxf.T +\n",
        "       h_ @ self.Whf.T +\n",
        "       self.bf.T\n",
        "    )\n",
        "\n",
        "    o_ = torch.sigmoid(\n",
        "       inputs @ self.Wxo.T +\n",
        "       h_ @ self.Who.T +\n",
        "       self.bo.T\n",
        "    )\n",
        "\n",
        "    c_hat = torch.tanh(\n",
        "        inputs @ self.Wxc.T +\n",
        "        h_ @ self.Whc.T +\n",
        "        self.bc.T\n",
        "    )\n",
        "\n",
        "    c_ = f_ * c_ + i_ * c_hat\n",
        "\n",
        "    h_ = o_ * torch.tanh(c_)\n",
        "\n",
        "    # outputs: (batch_size, hidden_size)\n",
        "\n",
        "    return h_, c_"
      ],
      "metadata": {
        "id": "No6upM6bFIAW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiRNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size, embedding_size, num_layers=1):\n",
        "    super(MultiRNN, self).__init__()\n",
        "\n",
        "    self.hidden_size = hidden_size\n",
        "    self.embed = nn.Embedding(input_size, embedding_size)\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    if num_layers == 1:\n",
        "      self.front_rnn = SimpleRNNLayer(embedding_size, hidden_size)\n",
        "    else:\n",
        "      self.front_rnn = nn.ModuleList()\n",
        "      for idx, layer_ in enumerate(range(num_layers)):\n",
        "        if idx == 0:\n",
        "          self.front_rnn.append(SimpleRNNLayer(embedding_size, hidden_size))\n",
        "        else:\n",
        "          self.front_rnn.append(SimpleRNNLayer(hidden_size, hidden_size))\n",
        "\n",
        "    self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    if self.num_layers == 1:\n",
        "      hidden_front = torch.zeros(inputs.shape[0], self.hidden_size, device=inputs.device)\n",
        "    else:\n",
        "      hidden_front = []\n",
        "      for _ in range(self.num_layers):\n",
        "        hidden_front.append(torch.zeros(inputs.shape[0], self.hidden_size, device=inputs.device))\n",
        "\n",
        "    # 1. embedding: (batch_size, seq_len, embed_dim)\n",
        "    inputs = self.embed(inputs)\n",
        "\n",
        "    # 2. transpose: (seq_len, batch_size, embed_dim)\n",
        "    inputs = torch.transpose(inputs, 0, 1)\n",
        "\n",
        "    front_outputs = []\n",
        "\n",
        "    # 3. x: (batch_size, embed_dim)\n",
        "    for x in inputs:\n",
        "      if self.num_layers == 1:\n",
        "        tmp_hidden = self.front_rnn(x, hidden_front)\n",
        "      else:\n",
        "        for idx, hidden_ in enumerate(hidden_front):\n",
        "          if idx == 0:\n",
        "            tmp_hidden = self.front_rnn[idx](x, hidden_)\n",
        "          else:\n",
        "            tmp_hidden = self.front_rnn[idx](tmp_hidden, hidden_)\n",
        "          hidden_front[idx] = tmp_hidden\n",
        "      front_outputs.append(tmp_hidden)\n",
        "\n",
        "    hidden = self.fc(tmp_hidden)\n",
        "\n",
        "    return hidden, front_outputs"
      ],
      "metadata": {
        "id": "Ybz47ybkF-2w"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiGRU(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size, embedding_size, num_layers=1):\n",
        "    super(MultiGRU, self).__init__()\n",
        "\n",
        "    self.hidden_size = hidden_size\n",
        "    self.embed = nn.Embedding(input_size, embedding_size)\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    if num_layers == 1:\n",
        "      self.front_rnn = SimpleGRULayer(embedding_size, hidden_size)\n",
        "    else:\n",
        "      self.front_rnn = nn.ModuleList()\n",
        "      for idx, layer_ in enumerate(range(num_layers)):\n",
        "        if idx == 0:\n",
        "          self.front_rnn.append(SimpleGRULayer(embedding_size, hidden_size))\n",
        "        else:\n",
        "          self.front_rnn.append(SimpleGRULayer(hidden_size, hidden_size))\n",
        "\n",
        "    self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    if self.num_layers == 1:\n",
        "      hidden_front = torch.zeros(inputs.shape[0], self.hidden_size, device=inputs.device)\n",
        "    else:\n",
        "      hidden_front = []\n",
        "      for _ in range(self.num_layers):\n",
        "        hidden_front.append(torch.zeros(inputs.shape[0], self.hidden_size, device=inputs.device))\n",
        "\n",
        "    # 1. embedding: (batch_size, seq_len, embed_dim)\n",
        "    inputs = self.embed(inputs)\n",
        "\n",
        "    # 2. transpose: (seq_len, batch_size, embed_dim)\n",
        "    inputs = torch.transpose(inputs, 0, 1)\n",
        "\n",
        "    front_outputs = []\n",
        "\n",
        "    # 3. x: (batch_size, embed_dim)\n",
        "    for x in inputs:\n",
        "      if self.num_layers == 1:\n",
        "        tmp_hidden = self.front_rnn(x, hidden_front)\n",
        "      else:\n",
        "        for idx, hidden_ in enumerate(hidden_front):\n",
        "          if idx == 0:\n",
        "            tmp_hidden = self.front_rnn[idx](x, hidden_)\n",
        "          else:\n",
        "            tmp_hidden = self.front_rnn[idx](tmp_hidden, hidden_)\n",
        "          hidden_front[idx] = tmp_hidden\n",
        "      front_outputs.append(tmp_hidden)\n",
        "\n",
        "    hidden = self.fc(tmp_hidden)\n",
        "\n",
        "    return hidden, front_outputs"
      ],
      "metadata": {
        "id": "x2edJmZrN2YS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiLSTM(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size, embedding_size, num_layers=1):\n",
        "    super(MultiLSTM, self).__init__()\n",
        "\n",
        "    self.hidden_size = hidden_size\n",
        "    self.embed = nn.Embedding(input_size, embedding_size)\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    if num_layers == 1:\n",
        "      self.front_rnn = SimpleLSTMLayer(embedding_size, hidden_size)\n",
        "    else:\n",
        "      self.front_rnn = nn.ModuleList()\n",
        "      for idx, layer_ in enumerate(range(num_layers)):\n",
        "        if idx == 0:\n",
        "          self.front_rnn.append(SimpleLSTMLayer(embedding_size, hidden_size))\n",
        "        else:\n",
        "          self.front_rnn.append(SimpleLSTMLayer(hidden_size, hidden_size))\n",
        "\n",
        "    self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    if self.num_layers == 1:\n",
        "      hidden_front = torch.zeros(inputs.shape[0], self.hidden_size, device=inputs.device)\n",
        "      hidden_cell = torch.zeros(inputs.shape[0], self.hidden_size, device=inputs.device)\n",
        "    else:\n",
        "      hidden_front = []\n",
        "      hidden_cell = []\n",
        "      for _ in range(self.num_layers):\n",
        "        hidden_front.append(torch.zeros(inputs.shape[0], self.hidden_size, device=inputs.device))\n",
        "        hidden_cell.append(torch.zeros(inputs.shape[0], self.hidden_size, device=inputs.device))\n",
        "\n",
        "    # 1. embedding: (batch_size, seq_len, embed_dim)\n",
        "    inputs = self.embed(inputs)\n",
        "\n",
        "    # 2. transpose: (seq_len, batch_size, embed_dim)\n",
        "    inputs = torch.transpose(inputs, 0, 1)\n",
        "\n",
        "    front_outputs = []\n",
        "\n",
        "    # 3. x: (batch_size, embed_dim)\n",
        "    for x in inputs:\n",
        "      if self.num_layers == 1:\n",
        "        tmp_hidden, tmp_cell = self.front_rnn(x, hidden_front, hidden_cell)\n",
        "      else:\n",
        "        for idx, (hidden_, cell_) in enumerate(zip(hidden_front, hidden_cell)):\n",
        "          if idx == 0:\n",
        "            tmp_hidden, tmp_cell = self.front_rnn[idx](x, hidden_, cell_)\n",
        "          else:\n",
        "            tmp_hidden, tmp_cell = self.front_rnn[idx](tmp_hidden, hidden_, cell_)\n",
        "          hidden_front[idx] = tmp_hidden\n",
        "          hidden_cell[idx] = tmp_cell\n",
        "      front_outputs.append(tmp_hidden)\n",
        "\n",
        "    hidden = self.fc(tmp_hidden)\n",
        "\n",
        "    return hidden, front_outputs"
      ],
      "metadata": {
        "id": "WtgsxTT7OP-t"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiBiRNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size, embedding_size, num_layers=1):\n",
        "    super(MultiBiRNN, self).__init__()\n",
        "\n",
        "    self.hidden_size = hidden_size\n",
        "    self.embed = nn.Embedding(input_size, embedding_size)\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    if num_layers == 1:\n",
        "      self.front_rnn = SimpleRNNLayer(embedding_size, hidden_size)\n",
        "      self.back_rnn = SimpleRNNLayer(embedding_size, hidden_size)\n",
        "    else:\n",
        "      self.front_rnn = nn.ModuleList()\n",
        "      self.back_rnn = nn.ModuleList()\n",
        "      for idx, layer_ in enumerate(range(num_layers)):\n",
        "        if idx == 0:\n",
        "          self.front_rnn.append(SimpleRNNLayer(embedding_size, hidden_size))\n",
        "          self.back_rnn.append(SimpleRNNLayer(embedding_size, hidden_size))\n",
        "        else:\n",
        "          self.front_rnn.append(SimpleRNNLayer(hidden_size, hidden_size))\n",
        "          self.back_rnn.append(SimpleRNNLayer(hidden_size, hidden_size))\n",
        "\n",
        "    self.fc = nn.Linear(2 * hidden_size, output_size)\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    if self.num_layers == 1:\n",
        "      hidden_front = torch.zeros(inputs.shape[0], self.hidden_size, device=inputs.device)\n",
        "      hidden_back = torch.zeros(inputs.shape[0], self.hidden_size, device=inputs.device)\n",
        "    else:\n",
        "      hidden_front = []\n",
        "      hidden_back = []\n",
        "      for _ in range(self.num_layers):\n",
        "        hidden_front.append(torch.zeros(inputs.shape[0], self.hidden_size, device=inputs.device))\n",
        "        hidden_back.append(torch.zeros(inputs.shape[0], self.hidden_size, device=inputs.device))\n",
        "\n",
        "    # 1. embedding: (batch_size, seq_len, embed_dim)\n",
        "    inputs = self.embed(inputs)\n",
        "\n",
        "    # 2. transpose: (seq_len, batch_size, embed_dim)\n",
        "    inputs = torch.transpose(inputs, 0, 1)\n",
        "\n",
        "    front_outputs = []\n",
        "    back_outputs = []\n",
        "\n",
        "    # 3. x: (batch_size, embed_dim)\n",
        "    for x in inputs:\n",
        "      if self.num_layers == 1:\n",
        "        tmp_hidden = self.front_rnn(x, hidden_front)\n",
        "      else:\n",
        "        for idx, hidden_ in enumerate(hidden_front):\n",
        "          if idx == 0:\n",
        "            tmp_hidden = self.front_rnn[idx](x, hidden_)\n",
        "          else:\n",
        "            tmp_hidden = self.front_rnn[idx](tmp_hidden, hidden_)\n",
        "          hidden_front[idx] = tmp_hidden\n",
        "      front_outputs.append(tmp_hidden)\n",
        "\n",
        "    # 3. x: (batch_size, embed_dim)\n",
        "    for x in reversed(inputs):\n",
        "      if self.num_layers == 1:\n",
        "        tmp_hidden2 = self.back_rnn(x, hidden_back)\n",
        "      else:\n",
        "        for idx, hidden_ in enumerate(hidden_back):\n",
        "          if idx == 0:\n",
        "            tmp_hidden2 = self.back_rnn[idx](x, hidden_)\n",
        "          else:\n",
        "            tmp_hidden2 = self.back_rnn[idx](tmp_hidden2, hidden_)\n",
        "          hidden_back[idx] = tmp_hidden2\n",
        "      back_outputs.append(tmp_hidden2)\n",
        "\n",
        "    back_outputs = back_outputs[::-1]\n",
        "\n",
        "    final_hidden = torch.cat((tmp_hidden, tmp_hidden2), dim=1)\n",
        "\n",
        "    hidden = self.fc(final_hidden)\n",
        "\n",
        "    return hidden, (front_outputs, back_outputs)"
      ],
      "metadata": {
        "id": "bGdChoV3hGf2"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiBiGRU(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size, embedding_size, num_layers=1):\n",
        "    super(MultiBiGRU, self).__init__()\n",
        "\n",
        "    self.hidden_size = hidden_size\n",
        "    self.embed = nn.Embedding(input_size, embedding_size)\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    if num_layers == 1:\n",
        "      self.front_rnn = SimpleGRULayer(embedding_size, hidden_size)\n",
        "      self.back_rnn = SimpleGRULayer(embedding_size, hidden_size)\n",
        "    else:\n",
        "      self.front_rnn = nn.ModuleList()\n",
        "      self.back_rnn = nn.ModuleList()\n",
        "      for idx, layer_ in enumerate(range(num_layers)):\n",
        "        if idx == 0:\n",
        "          self.front_rnn.append(SimpleGRULayer(embedding_size, hidden_size))\n",
        "          self.back_rnn.append(SimpleGRULayer(embedding_size, hidden_size))\n",
        "        else:\n",
        "          self.front_rnn.append(SimpleGRULayer(hidden_size, hidden_size))\n",
        "          self.back_rnn.append(SimpleGRULayer(hidden_size, hidden_size))\n",
        "\n",
        "    self.fc = nn.Linear(2*hidden_size, output_size)\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    if self.num_layers == 1:\n",
        "      hidden_front = torch.zeros(inputs.shape[0], self.hidden_size, device=inputs.device)\n",
        "      hidden_back = torch.zeros(inputs.shape[0], self.hidden_size, device=inputs.device)\n",
        "    else:\n",
        "      hidden_front = []\n",
        "      hidden_back = []\n",
        "      for _ in range(self.num_layers):\n",
        "        hidden_front.append(torch.zeros(inputs.shape[0], self.hidden_size, device=inputs.device))\n",
        "        hidden_back.append(torch.zeros(inputs.shape[0], self.hidden_size, device=inputs.device))\n",
        "\n",
        "    # 1. embedding: (batch_size, seq_len, embed_dim)\n",
        "    inputs = self.embed(inputs)\n",
        "\n",
        "    # 2. transpose: (seq_len, batch_size, embed_dim)\n",
        "    inputs = torch.transpose(inputs, 0, 1)\n",
        "\n",
        "    front_outputs = []\n",
        "    back_outputs = []\n",
        "\n",
        "    # 3. x: (batch_size, embed_dim)\n",
        "    for x in inputs:\n",
        "      if self.num_layers == 1:\n",
        "        tmp_hidden = self.front_rnn(x, hidden_front)\n",
        "      else:\n",
        "        for idx, hidden_ in enumerate(hidden_front):\n",
        "          if idx == 0:\n",
        "            tmp_hidden = self.front_rnn[idx](x, hidden_)\n",
        "          else:\n",
        "            tmp_hidden = self.front_rnn[idx](tmp_hidden, hidden_)\n",
        "          hidden_front[idx] = tmp_hidden\n",
        "      front_outputs.append(tmp_hidden)\n",
        "\n",
        "    for x in reversed(inputs):\n",
        "      if self.num_layers == 1:\n",
        "        tmp_hidden2 = self.back_rnn(x, hidden_back)\n",
        "      else:\n",
        "        for idx, hidden_ in enumerate(hidden_back):\n",
        "          if idx == 0:\n",
        "            tmp_hidden2 = self.back_rnn[idx](x, hidden_)\n",
        "          else:\n",
        "            tmp_hidden2 = self.back_rnn[idx](tmp_hidden2, hidden_)\n",
        "          hidden_back[idx] = tmp_hidden2\n",
        "      back_outputs.append(tmp_hidden2)\n",
        "\n",
        "    back_outputs = back_outputs[::-1]\n",
        "\n",
        "    final_hidden = torch.cat((tmp_hidden, tmp_hidden2), dim=1)\n",
        "\n",
        "    hidden = self.fc(final_hidden)\n",
        "\n",
        "    return hidden, (front_outputs, back_outputs)"
      ],
      "metadata": {
        "id": "ZSNAEoyukkKe"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiBiLSTM(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size, embedding_size, num_layers=1):\n",
        "    super(MultiBiLSTM, self).__init__()\n",
        "\n",
        "    self.hidden_size = hidden_size\n",
        "    self.embed = nn.Embedding(input_size, embedding_size)\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    if num_layers == 1:\n",
        "      self.front_rnn = SimpleLSTMLayer(embedding_size, hidden_size)\n",
        "      self.back_rnn = SimpleLSTMLayer(embedding_size, hidden_size)\n",
        "    else:\n",
        "      self.front_rnn = nn.ModuleList()\n",
        "      self.back_rnn = nn.ModuleList()\n",
        "      for idx, layer_ in enumerate(range(num_layers)):\n",
        "        if idx == 0:\n",
        "          self.front_rnn.append(SimpleLSTMLayer(embedding_size, hidden_size))\n",
        "          self.back_rnn.append(SimpleLSTMLayer(embedding_size, hidden_size))\n",
        "        else:\n",
        "          self.front_rnn.append(SimpleLSTMLayer(hidden_size, hidden_size))\n",
        "          self.back_rnn.append(SimpleLSTMLayer(hidden_size, hidden_size))\n",
        "\n",
        "    self.fc = nn.Linear(2*hidden_size, output_size)\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    if self.num_layers == 1:\n",
        "      hidden_front = torch.zeros(inputs.shape[0], self.hidden_size, device=inputs.device)\n",
        "      hidden_cell = torch.zeros(inputs.shape[0], self.hidden_size, device=inputs.device)\n",
        "      hidden_back = torch.zeros(inputs.shape[0], self.hidden_size, device=inputs.device)\n",
        "      hidden_cell2 = torch.zeros(inputs.shape[0], self.hidden_size, device=inputs.device)\n",
        "    else:\n",
        "      hidden_front = []\n",
        "      hidden_cell = []\n",
        "      hidden_back = []\n",
        "      hidden_cell2 = []\n",
        "      for _ in range(self.num_layers):\n",
        "        hidden_front.append(torch.zeros(inputs.shape[0], self.hidden_size, device=inputs.device))\n",
        "        hidden_cell.append(torch.zeros(inputs.shape[0], self.hidden_size, device=inputs.device))\n",
        "        hidden_back.append(torch.zeros(inputs.shape[0], self.hidden_size, device=inputs.device))\n",
        "        hidden_cell2.append(torch.zeros(inputs.shape[0], self.hidden_size, device=inputs.device))\n",
        "\n",
        "    # 1. embedding: (batch_size, seq_len, embed_dim)\n",
        "    inputs = self.embed(inputs)\n",
        "\n",
        "    # 2. transpose: (seq_len, batch_size, embed_dim)\n",
        "    inputs = torch.transpose(inputs, 0, 1)\n",
        "\n",
        "    front_outputs = []\n",
        "    back_outputs = []\n",
        "\n",
        "    # 3. x: (batch_size, embed_dim)\n",
        "    for x in inputs:\n",
        "      if self.num_layers == 1:\n",
        "        tmp_hidden, tmp_cell = self.front_rnn(x, hidden_front, hidden_cell)\n",
        "      else:\n",
        "        for idx, (hidden_, cell_) in enumerate(zip(hidden_front, hidden_cell)):\n",
        "          if idx == 0:\n",
        "            tmp_hidden, tmp_cell = self.front_rnn[idx](x, hidden_, cell_)\n",
        "          else:\n",
        "            tmp_hidden, tmp_cell = self.front_rnn[idx](tmp_hidden, hidden_, cell_)\n",
        "          hidden_front[idx] = tmp_hidden\n",
        "          hidden_cell[idx] = tmp_cell\n",
        "      front_outputs.append(tmp_hidden)\n",
        "\n",
        "    # 3. x: (batch_size, embed_dim)\n",
        "    for x in reversed(inputs):\n",
        "      if self.num_layers == 1:\n",
        "        tmp_hidden2, tmp_cell2 = self.back_rnn(x, hidden_back, hidden_cell2)\n",
        "      else:\n",
        "        for idx, (hidden_, cell_) in enumerate(zip(hidden_back, hidden_cell2)):\n",
        "          if idx == 0:\n",
        "            tmp_hidden2, tmp_cell2 = self.back_rnn[idx](x, hidden_, cell_)\n",
        "          else:\n",
        "            tmp_hidden2, tmp_cell2 = self.back_rnn[idx](tmp_hidden2, hidden_, cell_)\n",
        "          hidden_back[idx] = tmp_hidden2\n",
        "          hidden_cell2[idx] = tmp_cell2\n",
        "      back_outputs.append(tmp_hidden2)\n",
        "\n",
        "    final_hidden = torch.cat([tmp_hidden, tmp_hidden2], dim=1)\n",
        "\n",
        "    hidden = self.fc(final_hidden)\n",
        "\n",
        "    return hidden, (front_outputs, back_outputs)"
      ],
      "metadata": {
        "id": "AbtTwnv1l7CH"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MultiRNN(len(vocab), 128, 2, 128, num_layers=3)  # 定义的网络结构\n",
        "criterion = torch.nn.CrossEntropyLoss()  # 损失函数\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # 优化器\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # 设置设备\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoPk3QwqGozH",
        "outputId": "bae9b3cd-98ee-4dd9-81a0-b3af49a28a31"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model, metrics = train_model_new(\n",
        "    model=model,\n",
        "    dataloader=train_loader,\n",
        "    evalloader=test_loader,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    device=device,\n",
        "    epochs=10\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_AN8lf5G2wl",
        "outputId": "b0a2cfc7-2305-4ca2-e6ca-30155a983747"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10: 100%|██████████| 13/13 [00:07<00:00,  1.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.7101, AUC: 0.5016, Eval Loss: 0.7071, Eval AUC: 0.5044\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10: 100%|██████████| 13/13 [00:07<00:00,  1.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/10], Loss: 0.6885, AUC: 0.5496, Eval Loss: 0.6961, Eval AUC: 0.5083\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10: 100%|██████████| 13/13 [00:07<00:00,  1.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/10], Loss: 0.6778, AUC: 0.5843, Eval Loss: 0.6973, Eval AUC: 0.4993\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10: 100%|██████████| 13/13 [00:07<00:00,  1.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/10], Loss: 0.6677, AUC: 0.6108, Eval Loss: 0.7013, Eval AUC: 0.5067\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10: 100%|██████████| 13/13 [00:07<00:00,  1.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/10], Loss: 0.6558, AUC: 0.6254, Eval Loss: 0.7078, Eval AUC: 0.5082\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/10: 100%|██████████| 13/13 [00:07<00:00,  1.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/10], Loss: 0.6419, AUC: 0.6458, Eval Loss: 0.7166, Eval AUC: 0.5086\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/10: 100%|██████████| 13/13 [00:07<00:00,  1.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/10], Loss: 0.6175, AUC: 0.6753, Eval Loss: 0.7329, Eval AUC: 0.5053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/10: 100%|██████████| 13/13 [00:07<00:00,  1.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/10], Loss: 0.5891, AUC: 0.6938, Eval Loss: 0.7628, Eval AUC: 0.5046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/10: 100%|██████████| 13/13 [00:07<00:00,  1.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/10], Loss: 0.5583, AUC: 0.7245, Eval Loss: 0.8048, Eval AUC: 0.5071\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/10: 100%|██████████| 13/13 [00:07<00:00,  1.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/10], Loss: 0.5298, AUC: 0.7373, Eval Loss: 0.8404, Eval AUC: 0.5082\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = MultiGRU(len(vocab), 128, 2, 128, num_layers=3)  # 定义的网络结构\n",
        "criterion = torch.nn.CrossEntropyLoss()  # 损失函数\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # 优化器\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # 设置设备\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7iCWOZ_G7GP",
        "outputId": "5f88dadd-34b8-4cc1-ef90-d82b558df97c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model, metrics = train_model_new(\n",
        "    model=model,\n",
        "    dataloader=train_loader,\n",
        "    evalloader=test_loader,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    device=device,\n",
        "    epochs=10\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUpYWCvvOFgI",
        "outputId": "424ed71a-d247-45ab-9a85-8cade948aacc"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10: 100%|██████████| 13/13 [00:16<00:00,  1.30s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.7141, AUC: 0.5038, Eval Loss: 0.6926, Eval AUC: 0.5104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10: 100%|██████████| 13/13 [00:17<00:00,  1.32s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/10], Loss: 0.6901, AUC: 0.5370, Eval Loss: 0.6933, Eval AUC: 0.5254\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10: 100%|██████████| 13/13 [00:16<00:00,  1.30s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/10], Loss: 0.6845, AUC: 0.5621, Eval Loss: 0.6933, Eval AUC: 0.5403\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10: 100%|██████████| 13/13 [00:17<00:00,  1.31s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/10], Loss: 0.6777, AUC: 0.5779, Eval Loss: 0.6926, Eval AUC: 0.5563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10: 100%|██████████| 13/13 [00:16<00:00,  1.29s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/10], Loss: 0.6629, AUC: 0.6232, Eval Loss: 0.6846, Eval AUC: 0.6235\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/10: 100%|██████████| 13/13 [00:17<00:00,  1.31s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/10], Loss: 0.6147, AUC: 0.7220, Eval Loss: 0.6556, Eval AUC: 0.7010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/10: 100%|██████████| 13/13 [00:17<00:00,  1.31s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/10], Loss: 0.5495, AUC: 0.7941, Eval Loss: 0.5273, Eval AUC: 0.8184\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/10: 100%|██████████| 13/13 [00:16<00:00,  1.29s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/10], Loss: 0.5182, AUC: 0.8289, Eval Loss: 0.6148, Eval AUC: 0.7951\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/10: 100%|██████████| 13/13 [00:16<00:00,  1.30s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/10], Loss: 0.4686, AUC: 0.8604, Eval Loss: 0.5059, Eval AUC: 0.8384\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/10: 100%|██████████| 13/13 [00:16<00:00,  1.30s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/10], Loss: 0.3952, AUC: 0.9043, Eval Loss: 0.4822, Eval AUC: 0.8605\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = MultiLSTM(len(vocab), 128, 2, 128, num_layers=3)  # 定义的网络结构\n",
        "criterion = torch.nn.CrossEntropyLoss()  # 损失函数\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # 优化器\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # 设置设备\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ASxx8DYOJFr",
        "outputId": "e69a5236-d55e-484e-c11e-ab3859e87e80"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model, metrics = train_model_new(\n",
        "    model=model,\n",
        "    dataloader=train_loader,\n",
        "    evalloader=test_loader,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    device=device,\n",
        "    epochs=10\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPFdDbT7PJ43",
        "outputId": "139498fe-2dab-48b0-ea08-f9d85f82de76"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10: 100%|██████████| 13/13 [00:19<00:00,  1.50s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.6936, AUC: 0.5064, Eval Loss: 0.6943, Eval AUC: 0.4981\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10: 100%|██████████| 13/13 [00:20<00:00,  1.54s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/10], Loss: 0.6913, AUC: 0.5228, Eval Loss: 0.6920, Eval AUC: 0.5252\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10: 100%|██████████| 13/13 [00:19<00:00,  1.52s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/10], Loss: 0.6882, AUC: 0.5455, Eval Loss: 0.6871, Eval AUC: 0.5545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10: 100%|██████████| 13/13 [00:20<00:00,  1.55s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/10], Loss: 0.6777, AUC: 0.5739, Eval Loss: 0.6926, Eval AUC: 0.5771\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10: 100%|██████████| 13/13 [00:20<00:00,  1.56s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/10], Loss: 0.6671, AUC: 0.6024, Eval Loss: 0.6707, Eval AUC: 0.6036\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/10: 100%|██████████| 13/13 [00:20<00:00,  1.55s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/10], Loss: 0.6577, AUC: 0.6175, Eval Loss: 0.6748, Eval AUC: 0.6017\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/10: 100%|██████████| 13/13 [00:20<00:00,  1.54s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/10], Loss: 0.6458, AUC: 0.6408, Eval Loss: 0.6728, Eval AUC: 0.6538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/10: 100%|██████████| 13/13 [00:20<00:00,  1.55s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/10], Loss: 0.6301, AUC: 0.6588, Eval Loss: 0.6720, Eval AUC: 0.7202\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/10: 100%|██████████| 13/13 [00:20<00:00,  1.55s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/10], Loss: 0.6129, AUC: 0.6848, Eval Loss: 0.6624, Eval AUC: 0.6572\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/10: 100%|██████████| 13/13 [00:20<00:00,  1.55s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/10], Loss: 0.5697, AUC: 0.7878, Eval Loss: 0.5846, Eval AUC: 0.7489\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = MultiBiRNN(len(vocab), 128, 2, 128, num_layers=3)  # 定义的网络结构\n",
        "criterion = torch.nn.CrossEntropyLoss()  # 损失函数\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # 优化器\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # 设置设备\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTrxqkoQPPTO",
        "outputId": "ea75c563-16b4-444a-d33f-73c5ab0f9ee9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model, metrics = train_model_new(\n",
        "    model=model,\n",
        "    dataloader=train_loader,\n",
        "    evalloader=test_loader,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    device=device,\n",
        "    epochs=10\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJVzmXQnjGPx",
        "outputId": "232dc84c-bff5-4768-937a-877258241604"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10: 100%|██████████| 13/13 [00:12<00:00,  1.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.7054, AUC: 0.5358, Eval Loss: 0.6903, Eval AUC: 0.5704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10: 100%|██████████| 13/13 [00:10<00:00,  1.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/10], Loss: 0.6560, AUC: 0.6598, Eval Loss: 0.6761, Eval AUC: 0.6103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10: 100%|██████████| 13/13 [00:10<00:00,  1.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/10], Loss: 0.6141, AUC: 0.7238, Eval Loss: 0.6454, Eval AUC: 0.6809\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10: 100%|██████████| 13/13 [00:10<00:00,  1.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/10], Loss: 0.5898, AUC: 0.7504, Eval Loss: 0.6677, Eval AUC: 0.6457\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10: 100%|██████████| 13/13 [00:11<00:00,  1.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/10], Loss: 0.5332, AUC: 0.8113, Eval Loss: 0.6557, Eval AUC: 0.6859\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/10: 100%|██████████| 13/13 [00:10<00:00,  1.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/10], Loss: 0.4745, AUC: 0.8585, Eval Loss: 0.6473, Eval AUC: 0.7255\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/10: 100%|██████████| 13/13 [00:10<00:00,  1.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/10], Loss: 0.4105, AUC: 0.8960, Eval Loss: 0.6842, Eval AUC: 0.7426\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/10: 100%|██████████| 13/13 [00:10<00:00,  1.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/10], Loss: 0.3513, AUC: 0.9260, Eval Loss: 0.6931, Eval AUC: 0.7283\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/10: 100%|██████████| 13/13 [00:10<00:00,  1.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/10], Loss: 0.2852, AUC: 0.9539, Eval Loss: 0.7237, Eval AUC: 0.7399\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/10: 100%|██████████| 13/13 [00:11<00:00,  1.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/10], Loss: 0.2365, AUC: 0.9687, Eval Loss: 0.7878, Eval AUC: 0.7344\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = MultiBiGRU(len(vocab), 128, 2, 128, num_layers=3)  # 定义的网络结构\n",
        "criterion = torch.nn.CrossEntropyLoss()  # 损失函数\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # 优化器\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # 设置设备\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MbJWCN6joX-",
        "outputId": "72d6aa1a-5fc4-410d-ad0e-2d67be79b26a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model, metrics = train_model_new(\n",
        "    model=model,\n",
        "    dataloader=train_loader,\n",
        "    evalloader=test_loader,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    device=device,\n",
        "    epochs=10\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnXVUK5LlRFC",
        "outputId": "13832eed-e611-483e-b41e-2fed4e8ee66a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10: 100%|██████████| 13/13 [00:30<00:00,  2.33s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.7025, AUC: 0.5436, Eval Loss: 0.6764, Eval AUC: 0.6147\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10: 100%|██████████| 13/13 [00:29<00:00,  2.31s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/10], Loss: 0.6524, AUC: 0.6549, Eval Loss: 0.6471, Eval AUC: 0.6644\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10: 100%|██████████| 13/13 [00:30<00:00,  2.32s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/10], Loss: 0.5938, AUC: 0.7389, Eval Loss: 0.5943, Eval AUC: 0.7787\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10: 100%|██████████| 13/13 [00:30<00:00,  2.35s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/10], Loss: 0.5234, AUC: 0.8203, Eval Loss: 0.5583, Eval AUC: 0.8122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10: 100%|██████████| 13/13 [00:30<00:00,  2.35s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/10], Loss: 0.4629, AUC: 0.8620, Eval Loss: 0.5055, Eval AUC: 0.8385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/10: 100%|██████████| 13/13 [00:30<00:00,  2.34s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/10], Loss: 0.4184, AUC: 0.8903, Eval Loss: 0.5068, Eval AUC: 0.8583\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/10: 100%|██████████| 13/13 [00:30<00:00,  2.32s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/10], Loss: 0.4074, AUC: 0.8967, Eval Loss: 0.4547, Eval AUC: 0.8696\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/10: 100%|██████████| 13/13 [00:30<00:00,  2.36s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/10], Loss: 0.3418, AUC: 0.9293, Eval Loss: 0.4281, Eval AUC: 0.8875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/10: 100%|██████████| 13/13 [00:30<00:00,  2.33s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/10], Loss: 0.2984, AUC: 0.9460, Eval Loss: 0.4329, Eval AUC: 0.8905\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/10: 100%|██████████| 13/13 [00:30<00:00,  2.35s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/10], Loss: 0.3121, AUC: 0.9417, Eval Loss: 0.4490, Eval AUC: 0.8778\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = build_movie_vocab_chuncked(\"/content/aclImdb\", 256)\n",
        "print(f\"vocab size: {len(vocab)}\")\n",
        "train_data = ImbdDataSet(\"/content/aclImdb\", vocab, max_length=256, data_type='train')\n",
        "test_data = ImbdDataSet(\"/content/aclImdb\", vocab, max_length=256, data_type='test')\n",
        "train_loader = DataLoader(train_data, batch_size=1024, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=1024, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0EQQZmCqE-X",
        "outputId": "93c67839-47e1-434f-fbeb-9f636a13502e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab size: 5817\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = MultiBiLSTM(len(vocab), 128, 2, 128, num_layers=3)  # 定义的网络结构\n",
        "criterion = torch.nn.CrossEntropyLoss()  # 损失函数\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # 优化器\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # 设置设备\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eViMeuBXlWVm",
        "outputId": "6ba3efbc-c728-40c8-c290-4cf5651877f2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model, metrics = train_model_new(\n",
        "    model=model,\n",
        "    dataloader=train_loader,\n",
        "    evalloader=test_loader,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    device=device,\n",
        "    epochs=10\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0CtHOUPm0yZ",
        "outputId": "5e38442b-fd06-42b7-d9fb-c848d729bf75"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10: 100%|██████████| 25/25 [01:05<00:00,  2.63s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.6634, AUC: 0.6269, Eval Loss: 0.6061, Eval AUC: 0.7392\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10: 100%|██████████| 25/25 [01:08<00:00,  2.73s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/10], Loss: 0.5700, AUC: 0.7743, Eval Loss: 0.5283, Eval AUC: 0.8183\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10: 100%|██████████| 25/25 [01:07<00:00,  2.72s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/10], Loss: 0.5131, AUC: 0.8271, Eval Loss: 0.5320, Eval AUC: 0.8339\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10: 100%|██████████| 25/25 [01:08<00:00,  2.73s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/10], Loss: 0.4502, AUC: 0.8708, Eval Loss: 0.4589, Eval AUC: 0.8711\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10: 100%|██████████| 25/25 [01:08<00:00,  2.75s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/10], Loss: 0.3937, AUC: 0.9039, Eval Loss: 0.5053, Eval AUC: 0.8806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/10: 100%|██████████| 25/25 [01:09<00:00,  2.77s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/10], Loss: 0.3638, AUC: 0.9186, Eval Loss: 0.4692, Eval AUC: 0.8813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/10: 100%|██████████| 25/25 [01:09<00:00,  2.79s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/10], Loss: 0.3147, AUC: 0.9391, Eval Loss: 0.4876, Eval AUC: 0.8886\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/10: 100%|██████████| 25/25 [01:09<00:00,  2.79s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/10], Loss: 0.2876, AUC: 0.9492, Eval Loss: 0.4186, Eval AUC: 0.9015\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/10: 100%|██████████| 25/25 [01:08<00:00,  2.75s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/10], Loss: 0.2335, AUC: 0.9656, Eval Loss: 0.4480, Eval AUC: 0.9037\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/10: 100%|██████████| 25/25 [01:09<00:00,  2.77s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/10], Loss: 0.2247, AUC: 0.9687, Eval Loss: 0.4817, Eval AUC: 0.9017\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_pkg(model, dataloader, evalloader, criterion, optimizer, device, scheduler=None, epochs=10):\n",
        "    \"\"\"\n",
        "    训练模型的通用函数。\n",
        "\n",
        "    参数：\n",
        "    - model: 定义好的神经网络模型。\n",
        "    - dataloader: 数据加载器（训练集）。\n",
        "    - criterion: 损失函数。\n",
        "    - optimizer: 优化器。\n",
        "    - device: 训练设备（\"cuda\" 或 \"cpu\"）。\n",
        "    - epochs: 训练轮数。\n",
        "\n",
        "    返回：\n",
        "    - model: 训练后的模型。\n",
        "    - metrics: 包含训练过程中的损失和其他指标。\n",
        "    \"\"\"\n",
        "    model.to(device)  # 将模型加载到设备\n",
        "    metrics = {\"loss\": [], \"auc\": [], 'eval_loss': [], 'eval_auc': []}  # 记录每个 epoch 的损失\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()  # 设置模型为训练模式\n",
        "        if scheduler:\n",
        "          scheduler.step()\n",
        "        epoch_loss = 0.0\n",
        "        all_labels = []  # 存储真实标签\n",
        "        all_probs = []  # 存储预测概率\n",
        "        progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
        "\n",
        "        idx = 0\n",
        "        for batch in progress_bar:\n",
        "            idx += 1\n",
        "            inputs, labels = batch\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # 前向传播\n",
        "            outputs  = model(inputs)\n",
        "\n",
        "            # outputs = outputs.squeeze(-1)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # 反向传播\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "\n",
        "            grad_clipping(model, 1)\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            # 累加损失\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            probs = torch.softmax(outputs, dim=1)[:, 1].detach().cpu().numpy()  # 假设二分类，取第二类概率\n",
        "            all_probs.extend(probs)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "\n",
        "        # 记录每个 epoch 的平均损失\n",
        "        avg_loss = epoch_loss / len(dataloader)\n",
        "        metrics[\"loss\"].append(avg_loss)\n",
        "        epoch_auc = roc_auc_score(all_labels, all_probs)\n",
        "        metrics[\"auc\"].append(epoch_auc)\n",
        "\n",
        "        model.eval()\n",
        "        eval_loss = 0.0\n",
        "        eval_labels = []  # 存储真实标签\n",
        "        eval_probs = []  # 存储预测概率\n",
        "\n",
        "        for batch_eval in evalloader:\n",
        "          inputs_eval, labels_eval = batch_eval\n",
        "          inputs_eval, labels_eval = inputs_eval.to(device), labels_eval.to(device)\n",
        "          outputs_eval  = model(inputs_eval)\n",
        "          loss_eval = criterion(outputs_eval, labels_eval)\n",
        "          eval_loss += loss_eval.item()\n",
        "          probs = torch.softmax(outputs_eval, dim=1)[:,1].detach().cpu().numpy()\n",
        "          eval_probs.extend(probs)\n",
        "          eval_labels.extend(labels_eval.cpu().numpy())\n",
        "        eval_loss_avg = eval_loss / len(evalloader)\n",
        "        metrics['eval_loss'].append(eval_loss_avg)\n",
        "        eval_auc = roc_auc_score(eval_labels, eval_probs)\n",
        "        metrics['eval_auc'].append(eval_auc)\n",
        "#\n",
        "\n",
        "        # print(f\"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}, AUC: {epoch_auc:.4f}\")\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}, AUC: {epoch_auc:.4f}, Eval Loss: {eval_loss_avg:.4f}, Eval AUC: {eval_auc:.4f}\")\n",
        "\n",
        "    return model, metrics"
      ],
      "metadata": {
        "id": "lupvvAZ2pvbj"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SimpleGRUPkg(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_size, output_size, batch_size,\n",
        "                 dropout_prob=0.2, num_layers=1, bidirectional=False):\n",
        "        super(SimpleGRUPkg, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(num_embeddings=vocab_size,\n",
        "                                      embedding_dim=embed_dim,\n",
        "                                      padding_idx=0)\n",
        "\n",
        "        self.rnn = nn.GRU(batch_size, hidden_size, batch_first=True, dropout=dropout_prob,\n",
        "                          num_layers=num_layers, bidirectional=bidirectional)\n",
        "\n",
        "\n",
        "        if bidirectional:\n",
        "          self.fc = nn.Linear(2*hidden_size, output_size)\n",
        "        else:\n",
        "          self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        \"\"\"\n",
        "        inputs shape: (batch_size, seq_len)\n",
        "        返回:\n",
        "          - logits: (batch_size, output_size) 只在最后时间步输出\n",
        "          - h: (batch_size, hidden_size) 最后时间步的隐藏状态\n",
        "        \"\"\"\n",
        "        # 0. inputs: (batch_size, seq_len)\n",
        "        device = inputs.device\n",
        "\n",
        "        # 1. embedding: (batch_size, seq_len, embed_dim)\n",
        "        inputs = self.embedding(inputs)\n",
        "\n",
        "        # 2. (batch_size, seq_len, hidden_size)\n",
        "        inputs, _ = self.rnn(inputs)\n",
        "\n",
        "        # 3. (batch_size, 1, hidden_size)\n",
        "        outputs = self.fc(inputs[:,-1,:])\n",
        "\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "859Iq2K2qP0o"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleGRUPkg(len(vocab), 128, 64, 2, batch_size=128, bidirectional=True, num_layers=3)  # 定义的网络结构\n",
        "criterion = torch.nn.CrossEntropyLoss()  # 损失函数\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # 优化器\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # 设置设备\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVnF61K7vNWZ",
        "outputId": "79d61d01-e20f-480f-8fbc-7a2c9ada2d0e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model, metrics = train_model_pkg(\n",
        "    model=model,\n",
        "    dataloader=train_loader,\n",
        "    evalloader=test_loader,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    device=device,\n",
        "    epochs=30\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g28zjBuEvRTp",
        "outputId": "10758c68-d1d9-4cfa-95d4-c99e50f50289"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/30: 100%|██████████| 25/25 [00:07<00:00,  3.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/30], Loss: 0.6922, AUC: 0.5195, Eval Loss: 0.6934, Eval AUC: 0.5182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/30: 100%|██████████| 25/25 [00:07<00:00,  3.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/30], Loss: 0.6868, AUC: 0.5477, Eval Loss: 0.6954, Eval AUC: 0.5377\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/30: 100%|██████████| 25/25 [00:07<00:00,  3.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/30], Loss: 0.6811, AUC: 0.5675, Eval Loss: 0.6926, Eval AUC: 0.5450\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/30: 100%|██████████| 25/25 [00:06<00:00,  3.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/30], Loss: 0.6697, AUC: 0.5966, Eval Loss: 0.6916, Eval AUC: 0.5664\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/30: 100%|██████████| 25/25 [00:07<00:00,  3.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/30], Loss: 0.6543, AUC: 0.6214, Eval Loss: 0.6937, Eval AUC: 0.6196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/30: 100%|██████████| 25/25 [00:07<00:00,  3.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/30], Loss: 0.6201, AUC: 0.7187, Eval Loss: 0.6705, Eval AUC: 0.6431\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/30: 100%|██████████| 25/25 [00:06<00:00,  3.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/30], Loss: 0.6105, AUC: 0.7282, Eval Loss: 0.6464, Eval AUC: 0.7253\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/30: 100%|██████████| 25/25 [00:06<00:00,  3.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/30], Loss: 0.5614, AUC: 0.7658, Eval Loss: 0.6289, Eval AUC: 0.7420\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/30: 100%|██████████| 25/25 [00:07<00:00,  3.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/30], Loss: 0.5496, AUC: 0.7931, Eval Loss: 0.6368, Eval AUC: 0.7403\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/30: 100%|██████████| 25/25 [00:07<00:00,  3.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/30], Loss: 0.5418, AUC: 0.7989, Eval Loss: 0.6278, Eval AUC: 0.7748\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/30: 100%|██████████| 25/25 [00:06<00:00,  3.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [11/30], Loss: 0.4952, AUC: 0.8393, Eval Loss: 0.5301, Eval AUC: 0.8252\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/30: 100%|██████████| 25/25 [00:07<00:00,  3.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [12/30], Loss: 0.4402, AUC: 0.8768, Eval Loss: 0.4985, Eval AUC: 0.8463\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/30: 100%|██████████| 25/25 [00:07<00:00,  3.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [13/30], Loss: 0.3810, AUC: 0.9087, Eval Loss: 0.4855, Eval AUC: 0.8624\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/30: 100%|██████████| 25/25 [00:07<00:00,  3.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [14/30], Loss: 0.3289, AUC: 0.9338, Eval Loss: 0.4527, Eval AUC: 0.8890\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/30: 100%|██████████| 25/25 [00:06<00:00,  3.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [15/30], Loss: 0.2922, AUC: 0.9480, Eval Loss: 0.4291, Eval AUC: 0.9009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/30: 100%|██████████| 25/25 [00:06<00:00,  3.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [16/30], Loss: 0.2990, AUC: 0.9458, Eval Loss: 0.4609, Eval AUC: 0.9011\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/30: 100%|██████████| 25/25 [00:06<00:00,  3.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [17/30], Loss: 0.2485, AUC: 0.9620, Eval Loss: 0.4147, Eval AUC: 0.9120\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/30: 100%|██████████| 25/25 [00:07<00:00,  3.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [18/30], Loss: 0.2296, AUC: 0.9670, Eval Loss: 0.4069, Eval AUC: 0.9141\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/30: 100%|██████████| 25/25 [00:07<00:00,  3.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [19/30], Loss: 0.2037, AUC: 0.9736, Eval Loss: 0.4202, Eval AUC: 0.9149\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/30: 100%|██████████| 25/25 [00:06<00:00,  3.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [20/30], Loss: 0.1826, AUC: 0.9783, Eval Loss: 0.4189, Eval AUC: 0.9143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/30: 100%|██████████| 25/25 [00:07<00:00,  3.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [21/30], Loss: 0.1677, AUC: 0.9814, Eval Loss: 0.4403, Eval AUC: 0.9142\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/30: 100%|██████████| 25/25 [00:07<00:00,  3.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [22/30], Loss: 0.1470, AUC: 0.9848, Eval Loss: 0.4709, Eval AUC: 0.9185\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23/30: 100%|██████████| 25/25 [00:07<00:00,  3.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [23/30], Loss: 0.1297, AUC: 0.9878, Eval Loss: 0.5052, Eval AUC: 0.9137\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24/30: 100%|██████████| 25/25 [00:06<00:00,  3.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [24/30], Loss: 0.1411, AUC: 0.9867, Eval Loss: 0.5233, Eval AUC: 0.9140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25/30: 100%|██████████| 25/25 [00:06<00:00,  3.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [25/30], Loss: 0.1326, AUC: 0.9880, Eval Loss: 0.5077, Eval AUC: 0.9156\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26/30: 100%|██████████| 25/25 [00:07<00:00,  3.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [26/30], Loss: 0.1142, AUC: 0.9900, Eval Loss: 0.5545, Eval AUC: 0.9113\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27/30: 100%|██████████| 25/25 [00:06<00:00,  3.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [27/30], Loss: 0.1099, AUC: 0.9907, Eval Loss: 0.5440, Eval AUC: 0.9135\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28/30: 100%|██████████| 25/25 [00:07<00:00,  3.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [28/30], Loss: 0.0991, AUC: 0.9919, Eval Loss: 0.5275, Eval AUC: 0.9138\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29/30: 100%|██████████| 25/25 [00:07<00:00,  3.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [29/30], Loss: 0.0769, AUC: 0.9937, Eval Loss: 0.5639, Eval AUC: 0.9118\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30/30: 100%|██████████| 25/25 [00:07<00:00,  3.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [30/30], Loss: 0.0768, AUC: 0.9943, Eval Loss: 0.6097, Eval AUC: 0.9076\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SimpleRNNPkg(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_size, output_size, batch_size,\n",
        "                 dropout_prob=0.2, num_layers=1, bidirectional=False):\n",
        "        super(SimpleRNNPkg, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(num_embeddings=vocab_size,\n",
        "                                      embedding_dim=embed_dim,\n",
        "                                      padding_idx=0)\n",
        "\n",
        "        self.rnn = nn.RNN(batch_size, hidden_size, batch_first=True, dropout=dropout_prob,\n",
        "                          num_layers=num_layers, bidirectional=bidirectional)\n",
        "\n",
        "\n",
        "        if bidirectional:\n",
        "          self.fc = nn.Linear(2*hidden_size, output_size)\n",
        "        else:\n",
        "          self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        \"\"\"\n",
        "        inputs shape: (batch_size, seq_len)\n",
        "        返回:\n",
        "          - logits: (batch_size, output_size) 只在最后时间步输出\n",
        "          - h: (batch_size, hidden_size) 最后时间步的隐藏状态\n",
        "        \"\"\"\n",
        "        # 0. inputs: (batch_size, seq_len)\n",
        "        device = inputs.device\n",
        "\n",
        "        # 1. embedding: (batch_size, seq_len, embed_dim)\n",
        "        inputs = self.embedding(inputs)\n",
        "\n",
        "        # 2. (batch_size, seq_len, hidden_size)\n",
        "        inputs, _ = self.rnn(inputs)\n",
        "\n",
        "        # 3. (batch_size, 1, hidden_size)\n",
        "        outputs = self.fc(inputs[:,-1,:])\n",
        "\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "4GWsetLbvZmW"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleRNNPkg(len(vocab), 128, 64, 2, batch_size=128, bidirectional=True, num_layers=3)  # 定义的网络结构\n",
        "criterion = torch.nn.CrossEntropyLoss()  # 损失函数\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # 优化器\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # 设置设备\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acBPlcLUvfgx",
        "outputId": "49e22ab6-acfe-4e3e-d0c1-e2f82c1c344f"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model, metrics = train_model_pkg(\n",
        "    model=model,\n",
        "    dataloader=train_loader,\n",
        "    evalloader=test_loader,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    device=device,\n",
        "    epochs=30\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyOX5DThvjFX",
        "outputId": "24e4dcf5-50cd-4b3d-fd38-9974b15b2853"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/30: 100%|██████████| 25/25 [00:05<00:00,  4.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/30], Loss: 0.6963, AUC: 0.5059, Eval Loss: 0.6935, Eval AUC: 0.5089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/30: 100%|██████████| 25/25 [00:05<00:00,  4.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/30], Loss: 0.6917, AUC: 0.5277, Eval Loss: 0.6937, Eval AUC: 0.5084\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/30: 100%|██████████| 25/25 [00:05<00:00,  4.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/30], Loss: 0.6895, AUC: 0.5345, Eval Loss: 0.6950, Eval AUC: 0.5078\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/30: 100%|██████████| 25/25 [00:05<00:00,  4.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/30], Loss: 0.6858, AUC: 0.5489, Eval Loss: 0.6996, Eval AUC: 0.5061\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/30: 100%|██████████| 25/25 [00:05<00:00,  4.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/30], Loss: 0.6801, AUC: 0.5698, Eval Loss: 0.7090, Eval AUC: 0.5060\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/30: 100%|██████████| 25/25 [00:05<00:00,  4.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/30], Loss: 0.6761, AUC: 0.5803, Eval Loss: 0.7107, Eval AUC: 0.5043\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/30: 100%|██████████| 25/25 [00:05<00:00,  4.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/30], Loss: 0.6679, AUC: 0.5963, Eval Loss: 0.7217, Eval AUC: 0.5071\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/30: 100%|██████████| 25/25 [00:05<00:00,  4.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/30], Loss: 0.6583, AUC: 0.6105, Eval Loss: 0.7286, Eval AUC: 0.5047\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/30: 100%|██████████| 25/25 [00:05<00:00,  4.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/30], Loss: 0.6479, AUC: 0.6285, Eval Loss: 0.7424, Eval AUC: 0.5045\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/30: 100%|██████████| 25/25 [00:05<00:00,  4.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/30], Loss: 0.6386, AUC: 0.6410, Eval Loss: 0.7593, Eval AUC: 0.5044\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/30: 100%|██████████| 25/25 [00:05<00:00,  4.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [11/30], Loss: 0.6267, AUC: 0.6506, Eval Loss: 0.7698, Eval AUC: 0.5032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/30: 100%|██████████| 25/25 [00:05<00:00,  4.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [12/30], Loss: 0.6084, AUC: 0.6731, Eval Loss: 0.8029, Eval AUC: 0.5076\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/30: 100%|██████████| 25/25 [00:05<00:00,  4.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [13/30], Loss: 0.5960, AUC: 0.6876, Eval Loss: 0.8190, Eval AUC: 0.5049\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/30: 100%|██████████| 25/25 [00:05<00:00,  4.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [14/30], Loss: 0.5838, AUC: 0.6984, Eval Loss: 0.8597, Eval AUC: 0.5062\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/30: 100%|██████████| 25/25 [00:05<00:00,  4.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [15/30], Loss: 0.5689, AUC: 0.7100, Eval Loss: 0.8835, Eval AUC: 0.5028\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/30: 100%|██████████| 25/25 [00:05<00:00,  4.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [16/30], Loss: 0.5526, AUC: 0.7291, Eval Loss: 0.9206, Eval AUC: 0.5084\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/30: 100%|██████████| 25/25 [00:05<00:00,  4.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [17/30], Loss: 0.5452, AUC: 0.7290, Eval Loss: 0.9492, Eval AUC: 0.5044\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/30: 100%|██████████| 25/25 [00:05<00:00,  4.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [18/30], Loss: 0.5367, AUC: 0.7385, Eval Loss: 0.9859, Eval AUC: 0.5093\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/30: 100%|██████████| 25/25 [00:05<00:00,  4.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [19/30], Loss: 0.5241, AUC: 0.7451, Eval Loss: 1.0267, Eval AUC: 0.5066\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/30: 100%|██████████| 25/25 [00:05<00:00,  4.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [20/30], Loss: 0.5141, AUC: 0.7530, Eval Loss: 1.0638, Eval AUC: 0.5047\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/30: 100%|██████████| 25/25 [00:05<00:00,  4.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [21/30], Loss: 0.5086, AUC: 0.7560, Eval Loss: 1.0688, Eval AUC: 0.5082\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/30: 100%|██████████| 25/25 [00:05<00:00,  4.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [22/30], Loss: 0.5027, AUC: 0.7602, Eval Loss: 1.1112, Eval AUC: 0.5071\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23/30: 100%|██████████| 25/25 [00:05<00:00,  4.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [23/30], Loss: 0.4971, AUC: 0.7656, Eval Loss: 1.0995, Eval AUC: 0.5106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24/30: 100%|██████████| 25/25 [00:05<00:00,  4.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [24/30], Loss: 0.4911, AUC: 0.7695, Eval Loss: 1.1826, Eval AUC: 0.5037\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25/30: 100%|██████████| 25/25 [00:05<00:00,  4.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [25/30], Loss: 0.4902, AUC: 0.7689, Eval Loss: 1.1496, Eval AUC: 0.5120\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26/30: 100%|██████████| 25/25 [00:05<00:00,  4.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [26/30], Loss: 0.4907, AUC: 0.7716, Eval Loss: 1.2109, Eval AUC: 0.5043\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27/30: 100%|██████████| 25/25 [00:05<00:00,  4.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [27/30], Loss: 0.4858, AUC: 0.7724, Eval Loss: 1.2414, Eval AUC: 0.5017\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28/30: 100%|██████████| 25/25 [00:05<00:00,  4.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [28/30], Loss: 0.4792, AUC: 0.7787, Eval Loss: 1.2470, Eval AUC: 0.5078\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29/30: 100%|██████████| 25/25 [00:05<00:00,  4.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [29/30], Loss: 0.4806, AUC: 0.7760, Eval Loss: 1.2835, Eval AUC: 0.5057\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30/30: 100%|██████████| 25/25 [00:05<00:00,  4.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [30/30], Loss: 0.4802, AUC: 0.7747, Eval Loss: 1.2346, Eval AUC: 0.5077\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SimpleLSTMPkg(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_size, output_size, batch_size,\n",
        "                 dropout_prob=0.2, num_layers=1, bidirectional=False):\n",
        "        super(SimpleLSTMPkg, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(num_embeddings=vocab_size,\n",
        "                                      embedding_dim=embed_dim,\n",
        "                                      padding_idx=0)\n",
        "\n",
        "        self.rnn = nn.LSTM(batch_size, hidden_size, batch_first=True, dropout=dropout_prob,\n",
        "                           num_layers=num_layers, bidirectional=bidirectional)\n",
        "\n",
        "\n",
        "        if bidirectional:\n",
        "          self.fc = nn.Linear(2*hidden_size, output_size)\n",
        "        else:\n",
        "          self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        \"\"\"\n",
        "        inputs shape: (batch_size, seq_len)\n",
        "        返回:\n",
        "          - logits: (batch_size, output_size) 只在最后时间步输出\n",
        "          - h: (batch_size, hidden_size) 最后时间步的隐藏状态\n",
        "        \"\"\"\n",
        "        # 0. inputs: (batch_size, seq_len)\n",
        "        device = inputs.device\n",
        "\n",
        "        # 1. embedding: (batch_size, seq_len, embed_dim)\n",
        "        inputs = self.embedding(inputs)\n",
        "\n",
        "        # 2. (batch_size, seq_len, hidden_size)\n",
        "        inputs, _ = self.rnn(inputs)\n",
        "\n",
        "        # 3. (batch_size, 1, hidden_size)\n",
        "        outputs = self.fc(inputs[:,-1,:])\n",
        "\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "czUkEpR8vlY8"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleLSTMPkg(len(vocab), 128, 64, 2, batch_size=128, num_layers=3, bidirectional=True)  # 定义的网络结构\n",
        "criterion = torch.nn.CrossEntropyLoss()  # 损失函数\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # 优化器\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # 设置设备\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MP2faTsRvqk3",
        "outputId": "5f3ba8ca-5442-4e77-c64d-4d804ffc36ba"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model, metrics = train_model_pkg(\n",
        "    model=model,\n",
        "    dataloader=train_loader,\n",
        "    evalloader=test_loader,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    device=device,\n",
        "    epochs=10\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoZBEbxrvuUa",
        "outputId": "e4d61f7b-1d7f-4865-bbfc-23b46ed76e62"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10: 100%|██████████| 25/25 [00:06<00:00,  3.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.6927, AUC: 0.5111, Eval Loss: 0.6929, Eval AUC: 0.5096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10: 100%|██████████| 25/25 [00:06<00:00,  3.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/10], Loss: 0.6887, AUC: 0.5381, Eval Loss: 0.6904, Eval AUC: 0.5435\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10: 100%|██████████| 25/25 [00:06<00:00,  3.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/10], Loss: 0.6794, AUC: 0.5741, Eval Loss: 0.6873, Eval AUC: 0.6219\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10: 100%|██████████| 25/25 [00:07<00:00,  3.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/10], Loss: 0.6664, AUC: 0.6042, Eval Loss: 0.6801, Eval AUC: 0.6561\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10: 100%|██████████| 25/25 [00:06<00:00,  3.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/10], Loss: 0.6372, AUC: 0.6714, Eval Loss: 0.6564, Eval AUC: 0.6790\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/10: 100%|██████████| 25/25 [00:06<00:00,  3.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/10], Loss: 0.6158, AUC: 0.7097, Eval Loss: 0.6201, Eval AUC: 0.7168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/10: 100%|██████████| 25/25 [00:06<00:00,  3.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/10], Loss: 0.5843, AUC: 0.7473, Eval Loss: 0.6276, Eval AUC: 0.7170\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/10: 100%|██████████| 25/25 [00:06<00:00,  3.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/10], Loss: 0.5614, AUC: 0.7695, Eval Loss: 0.6272, Eval AUC: 0.7193\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/10: 100%|██████████| 25/25 [00:06<00:00,  3.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/10], Loss: 0.5721, AUC: 0.7571, Eval Loss: 0.6310, Eval AUC: 0.7124\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/10: 100%|██████████| 25/25 [00:06<00:00,  3.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/10], Loss: 0.5935, AUC: 0.7366, Eval Loss: 0.6624, Eval AUC: 0.6697\n"
          ]
        }
      ]
    }
  ]
}